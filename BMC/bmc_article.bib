% bmc_article.bib
% 
%  An example of bibtex entries.
%  Entries taken from BMC instructions for authors page.

% uncomment next line to make author-year bibliography
% @settings{label, options="nameyear"}

@article{blank,
    author  = {}, 
    title   = {},
    journal = {}, 
    year    = {},
    month   = {}, 
    volume  = {}, 
    number  = {}, 
    pages   = {},
    note    = {} 
}    

@misc{RN20,
   author = {Garland, Michael and Heckbert, Paul S.},
   title = {Surface simplification using quadric error metrics},
   publisher = {ACM Press/Addison-Wesley Publishing Co.},
   pages = {209–216},
   keywords = {level of detail, mutiresolution modeling, non-manifold, pair contraction, surface simplification},
   DOI = {10.1145/258734.258849},
   url = {https://doi.org/10.1145/258734.258849},
   year = {1997},
   type = {Conference Paper}
}

@article{RN59,
   author = {Luebke, D. P.},
   title = {A developer's survey of polygonal simplification algorithms},
   journal = {IEEE Computer Graphics and Applications},
   volume = {21},
   number = {3},
   pages = {24-35},
   ISSN = {1558-1756},
   DOI = {10.1109/38.920624},
   year = {2001},
   type = {Journal Article}
}

@inproceedings{RN12,
   author = {Leibnitz, Kenji and Hoßfeld, Tobias and Wakamiya, Naoki and Murata, Masayuki},
   title = {Peer-to-Peer vs. Client/Server: Reliability and Efficiency of a Content Distribution Service},
   booktitle = {Managing Traffic Performance in Converged Networks},
   editor = {Mason, Lorne and Drwiega, Tadeusz and Yan, James},
   publisher = {Springer Berlin Heidelberg},
   pages = {1161-1172},
   abstract = {In this paper we evaluate the performance of a content distribution service with respect to reliability and efficiency. The considered technology for realizing such a service can either be a traditional client/server (CS) architecture or a peer-to-peer (P2P) network. In CS, the capacity of the server is the bottleneck and has to be dimensioned in such a way that all requests can be accommodated at any time, while a P2P system does not burden a single server since the content is distributed in the network among sharing peers. However, corrupted or fake files may diminish the reliability of the P2P service due to downloading of useless contents. We compare a CS system to P2P and evaluate the downloading time, success ratio, and fairness while considering flash crowd arrivals and corrupted contents.},
   ISBN = {978-3-540-72990-7},
   type = {Conference Proceedings}
}

@book{RN19,
   author = {Cignoni, Paolo and Callieri, Marco and Corsini, Massimiliano and Dellepiane, Matteo and Ganovelli, Fabio and Ranzuglia, Guido},
   title = {MeshLab: an Open-Source Mesh Processing Tool},
   volume = {1},
   pages = {129-136},
   DOI = {10.2312/LocalChapterEvents/ItalChap/ItalianChapConf2008/129-136},
   year = {2008},
   type = {Book}
}

@inproceedings{RN64,
   author = {Butnaru, T. and Girbacia, F.},
   title = {Collaborative Pre-surgery Planning in a Tele-immersive Environment Using VR Technology},
   booktitle = {International Conference on Advancements of Medicine and Health Care through Technology},
   editor = {Vlad, Simona and Ciupa, Radu V. and Nicu, Anca I.},
   publisher = {Springer Berlin Heidelberg},
   pages = {9-14},
   abstract = {The goal of this paper is to present a new way to use virtual reality technology to create a collaborative pre-surgery planning with purpose of reducing the time of bone surgery operations. The method presented in this paper can be used by one or more medical teams, who can collaborate remotely, immersed in a tele-immersive environment, based on networked CAVE’s systems and other stereoscopic desktop displays such as Reachin® Display [6] or classical desktop monitors with stereo capabilities. Surgeons can analyze and manipulate virtual representation of patient’s bones using 6DOF tracking devices, haptic feedback devices or voice commands. The virtual bones of patients are obtained using a 3D scanner. Surgeons have also a visual contact of which of them, using audio-video conference technologies embedded in virtual reality scene. This paper makes a wider description of the simulator, specifying the main modules and characteristics of the developed architecture. Finally, it is described in an experiment the process carried out for tele-immersive pre-surgery planning of a femur fracture.},
   ISBN = {978-3-642-04292-8},
   type = {Conference Proceedings}
}

@article{RN62,
   author = {Einav, Yael and Gopher, Daniel and Kara, Itzik and Ben-Yosef, Orna and Lawn, Margaret and Laufer, Neri and Liebergall, Meir and Donchin, Yoel},
   title = {Preoperative Briefing in the Operating Room: Shared Cognition, Teamwork, and Patient Safety},
   journal = {Chest},
   volume = {137},
   number = {2},
   pages = {443-449},
   abstract = {Contemporary preoperative team briefings conducted to improve patient safety focus mainly on supplying identification details regarding the patient and the surgical procedure. Drawing on cognitive theory principles, in this study a briefing protocol was developed that presents a broader perspective model of the patient and the planned procedure. In addition to customary identification details and drug sensitivities, the new briefing also includes review of significant background information, needed equipment, planned surgery stages, and so forth. The briefing content was developed following 130 continuous, nonstructured observations conducted in gynecologic and orthopedic operating rooms. The briefing form was designed as a large poster hung in a visible position on the operating room wall. The poster guides the team members (ie, nurses, surgeons, and anesthesiologists) in their conduct. Briefing is conducted orally, and no written records are required. The number of nonroutine events (ie, situations that, if not corrected, might lead to patient harm) observed in the 130 surgeries conducted without briefing was compared with the number of events in 102 surgeries in which briefing was conducted. There was a 25% reduction in the number of nonroutine events when briefing was conducted and a significant increase in the number of surgeries in which no nonroutine event was observed. Team members evaluated the briefing as most valuable for their own work, the teamwork, and patient safety. Following the study, the new briefing format was accepted and adopted for routine use. Team briefings designed to supply a broader-perspective surgery model may be an easy-to-apply tool to reduce the number of nonroutine events during surgery and increase patient safety.},
   ISSN = {0012-3692},
   DOI = {https://doi.org/10.1378/chest.08-1732},
   url = {https://www.sciencedirect.com/science/article/pii/S0012369210600918},
   year = {2010},
   type = {Journal Article}
}

@article{RN47,
   author = {Whyms, B. J. and Vorperian, H. K. and Gentry, L. R. and Schimek, E. M. and Bersu, E. T. and Chung, M. K.},
   title = {The effect of computed tomographic scanner parameters and 3-dimensional volume rendering techniques on the accuracy of linear, angular, and volumetric measurements of the mandible},
   journal = {Oral Surg Oral Med Oral Pathol Oral Radiol},
   volume = {115},
   number = {5},
   pages = {682-91},
   note = {2212-4411
Whyms, Brian J
Vorperian, Houri K
Gentry, Lindell R
Schimek, Eugene M
Bersu, Edward T
Chung, Moo K
P30 HD003352/HD/NICHD NIH HHS/United States
R01 DC006282/DC/NIDCD NIH HHS/United States
P30 HD03352/HD/NICHD NIH HHS/United States
R01 DC6282/DC/NIDCD NIH HHS/United States
Comparative Study
Journal Article
Research Support, N.I.H., Extramural
United States
2013/04/23
Oral Surg Oral Med Oral Pathol Oral Radiol. 2013 May;115(5):682-91. doi: 10.1016/j.oooo.2013.02.008.},
   abstract = {OBJECTIVES: This study investigates the effect of scanning parameters on the accuracy of measurements from three-dimensional (3D), multi-detector computed tomography (MDCT) mandible renderings. A broader range of acceptable parameters can increase the availability of computed tomographic (CT) studies for retrospective analysis. STUDY DESIGN: Three human mandibles and a phantom object were scanned using 18 combinations of slice thickness, field of view (FOV), and reconstruction algorithm and 3 different threshold-based segmentations. Measurements of 3D computed tomography (3DCT) models and specimens were compared. RESULTS: Linear and angular measurements were accurate, irrespective of scanner parameters or rendering technique. Volume measurements were accurate with a slice thickness of 1.25 mm, but not 2.5 mm. Surface area measurements were consistently inflated. CONCLUSIONS: Linear, angular, and volumetric measurements of mandible 3D MDCT models can be confidently obtained from a range of parameters and rendering techniques. Slice thickness is the primary factor affecting volume measurements. These findings should also apply to 3D rendering using cone-beam CT (CBCT).},
   keywords = {Adult
Algorithms
Alveolar Process/anatomy & histology/diagnostic imaging
Anatomic Landmarks/anatomy & histology/diagnostic imaging
Cephalometry/methods/statistics & numerical data
Child
Chin/anatomy & histology/diagnostic imaging
Humans
Image Processing, Computer-Assisted/*methods/statistics & numerical data
Imaging, Three-Dimensional/*methods/statistics & numerical data
Mandible/anatomy & histology/*diagnostic imaging
Mandibular Condyle/anatomy & histology/diagnostic imaging
Multidetector Computed Tomography/instrumentation/*methods/statistics & numerical
data
Phantoms, Imaging
Polymers
Reference Standards
Retrospective Studies
*Tomography Scanners, X-Ray Computed},
   ISSN = {2212-4403 (Print)},
   DOI = {10.1016/j.oooo.2013.02.008},
   year = {2013},
   type = {Journal Article}
}

@article{RN53,
   author = {Menze, B. H. and Jakab, A. and Bauer, S. and Kalpathy-Cramer, J. and Farahani, K. and Kirby, J. and Burren, Y. and Porz, N. and Slotboom, J. and Wiest, R. and Lanczi, L. and Gerstner, E. and Weber, M. A. and Arbel, T. and Avants, B. B. and Ayache, N. and Buendia, P. and Collins, D. L. and Cordier, N. and Corso, J. J. and Criminisi, A. and Das, T. and Delingette, H. and Demiralp, Ç and Durst, C. R. and Dojat, M. and Doyle, S. and Festa, J. and Forbes, F. and Geremia, E. and Glocker, B. and Golland, P. and Guo, X. and Hamamci, A. and Iftekharuddin, K. M. and Jena, R. and John, N. M. and Konukoglu, E. and Lashkari, D. and Mariz, J. A. and Meier, R. and Pereira, S. and Precup, D. and Price, S. J. and Raviv, T. R. and Reza, S. M. and Ryan, M. and Sarikaya, D. and Schwartz, L. and Shin, H. C. and Shotton, J. and Silva, C. A. and Sousa, N. and Subbanna, N. K. and Szekely, G. and Taylor, T. J. and Thomas, O. M. and Tustison, N. J. and Unal, G. and Vasseur, F. and Wintermark, M. and Ye, D. H. and Zhao, L. and Zhao, B. and Zikic, D. and Prastawa, M. and Reyes, M. and Van Leemput, K.},
   title = {The Multimodal Brain Tumor Image Segmentation Benchmark (BRATS)},
   journal = {IEEE Trans Med Imaging},
   volume = {34},
   number = {10},
   pages = {1993-2024},
   note = {1558-254x
Menze, Bjoern H
Jakab, Andras
Bauer, Stefan
Kalpathy-Cramer, Jayashree
Farahani, Keyvan
Kirby, Justin
Burren, Yuliya
Porz, Nicole
Slotboom, Johannes
Wiest, Roland
Lanczi, Levente
Gerstner, Elizabeth
Weber, Marc-André
Arbel, Tal
Avants, Brian B
Ayache, Nicholas
Buendia, Patricia
Collins, D Louis
Cordier, Nicolas
Corso, Jason J
Criminisi, Antonio
Das, Tilak
Delingette, Hervé
Demiralp, Çağatay
Durst, Christopher R
Dojat, Michel
Doyle, Senan
Festa, Joana
Forbes, Florence
Geremia, Ezequiel
Glocker, Ben
Golland, Polina
Guo, Xiaotao
Hamamci, Andac
Iftekharuddin, Khan M
Jena, Raj
John, Nigel M
Konukoglu, Ender
Lashkari, Danial
Mariz, José Antonió
Meier, Raphael
Pereira, Sérgio
Precup, Doina
Price, Stephen J
Raviv, Tammy Riklin
Reza, Syed M S
Ryan, Michael
Sarikaya, Duygu
Schwartz, Lawrence
Shin, Hoo-Chang
Shotton, Jamie
Silva, Carlos A
Sousa, Nuno
Subbanna, Nagesh K
Szekely, Gabor
Taylor, Thomas J
Thomas, Owen M
Tustison, Nicholas J
Unal, Gozde
Vasseur, Flor
Wintermark, Max
Ye, Dong Hye
Zhao, Liang
Zhao, Binsheng
Zikic, Darko
Prastawa, Marcel
Reyes, Mauricio
Van Leemput, Koen
P41-RR14075/RR/NCRR NIH HHS/United States
P41-RR13218/RR/NCRR NIH HHS/United States
P41-EB-015902/EB/NIBIB NIH HHS/United States
U54 EB005149/EB/NIBIB NIH HHS/United States
NIHR/CS/009/011/DH_/Department of Health/United Kingdom
P41 RR013218/RR/NCRR NIH HHS/United States
R01 EB013565/EB/NIBIB NIH HHS/United States
U01 CA154601/CA/NCI NIH HHS/United States
R01EB013565/EB/NIBIB NIH HHS/United States
R15CA115464/CA/NCI NIH HHS/United States
P41 EB015902/EB/NIBIB NIH HHS/United States
U54-EB005149/EB/NIBIB NIH HHS/United States
P41 RR014075/RR/NCRR NIH HHS/United States
R15 CA115464/CA/NCI NIH HHS/United States
Journal Article
Research Support, N.I.H., Extramural
Research Support, Non-U.S. Gov't
Review
United States
2014/12/11
IEEE Trans Med Imaging. 2015 Oct;34(10):1993-2024. doi: 10.1109/TMI.2014.2377694. Epub 2014 Dec 4.},
   abstract = {In this paper we report the set-up and results of the Multimodal Brain Tumor Image Segmentation Benchmark (BRATS) organized in conjunction with the MICCAI 2012 and 2013 conferences. Twenty state-of-the-art tumor segmentation algorithms were applied to a set of 65 multi-contrast MR scans of low- and high-grade glioma patients-manually annotated by up to four raters-and to 65 comparable scans generated using tumor image simulation software. Quantitative evaluations revealed considerable disagreement between the human raters in segmenting various tumor sub-regions (Dice scores in the range 74%-85%), illustrating the difficulty of this task. We found that different algorithms worked best for different sub-regions (reaching performance comparable to human inter-rater variability), but that no single algorithm ranked in the top for all sub-regions simultaneously. Fusing several good algorithms using a hierarchical majority vote yielded segmentations that consistently ranked above all individual algorithms, indicating remaining opportunities for further methodological improvements. The BRATS image data and manual annotations continue to be publicly available through an online evaluation system as an ongoing benchmarking resource.},
   keywords = {Algorithms
Benchmarking
Glioma/pathology
Humans
*Magnetic Resonance Imaging/methods/standards
*Neuroimaging/methods/standards},
   ISSN = {0278-0062 (Print)
0278-0062},
   DOI = {10.1109/tmi.2014.2377694},
   year = {2015},
   type = {Journal Article}
}

@article{RN7,
   author = {Ford, Jonathan M. and Decker, Summer J.},
   title = {Computed tomography slice thickness and its effects on three-dimensional reconstruction of anatomical structures},
   journal = {Journal of Forensic Radiology and Imaging},
   volume = {4},
   pages = {43-46},
   abstract = {Objectives Computed Tomography (CT) scan parameters such as slice thickness have a direct impact on any 3D models derived from the volumetric data. Higher slice thickness spacing leads to loss of resolution quality in the visualizations. Materials and methods Twenty CT head scans were acquired at a 0.625mm slice thickness. These data sets were resliced a range of 1–5mm slice thicknesses. The resultant 3D models of the skull were compared using the 0.625mm model as a standard. Differences in surface area, volume and part-to-part comparison were analyzed. Results and conclusions There were significant differences in surface area, volume and part-to-part comparison analyses from the 0.625mm skulls as determined with One-way ANOVA by a p-value less than 0.05. Part-to-part comparison proved to have the greatest sensitivity for detecting geometric differences between slice thickness treatments. This study proposes using a 1.25mm maximum slice thickness when forensic practitioners require 3D reconstruction in their casework.},
   keywords = {Forensic
Computed tomography
3D reconstruction
Crania
Slice thickness
Visualization
Post mortem},
   ISSN = {2212-4780},
   DOI = {https://doi.org/10.1016/j.jofri.2015.10.004},
   url = {https://www.sciencedirect.com/science/article/pii/S2212478015300204},
   year = {2016},
   type = {Journal Article}
}

@book{RN52,
   author = {Milletari, Fausto and Navab, Nassir and Ahmadi, Seyed-Ahmad},
   title = {V-Net: Fully Convolutional Neural Networks for Volumetric Medical Image Segmentation},
   pages = {565-571},
   DOI = {10.1109/3DV.2016.79},
   year = {2016},
   type = {Book}
}

@article{RN56,
   author = {Summers, R. M.},
   title = {Progress in Fully Automated Abdominal CT Interpretation},
   journal = {AJR Am J Roentgenol},
   volume = {207},
   number = {1},
   pages = {67-79},
   note = {1546-3141
Summers, Ronald M
Z01 CL040003-06/Intramural NIH HHS/United States
Z01 CL040004-05/Intramural NIH HHS/United States
Journal Article
Review
United States
2016/04/22
AJR Am J Roentgenol. 2016 Jul;207(1):67-79. doi: 10.2214/AJR.15.15996. Epub 2016 Apr 21.},
   abstract = {OBJECTIVE: Automated analysis of abdominal CT has advanced markedly over just the last few years. Fully automated assessment of organs, lymph nodes, adipose tissue, muscle, bowel, spine, and tumors are some examples where tremendous progress has been made. Computer-aided detection of lesions has also improved dramatically. CONCLUSION: This article reviews the progress and provides insights into what is in store in the near future for automated analysis for abdominal CT, ultimately leading to fully automated interpretation.},
   keywords = {Automation
Forecasting
Humans
Radiographic Image Interpretation, Computer-Assisted/*methods
*Radiography, Abdominal
*Tomography, X-Ray Computed
Ct
computer-aided detection
image processing
segmentation
volumetrics},
   ISSN = {0361-803X (Print)
0361-803x},
   DOI = {10.2214/ajr.15.15996},
   year = {2016},
   type = {Journal Article}
}

@article{RN43,
   author = {Yang, Q. and Xie, B. and Hu, M. and Sun, X. and Huang, X. and Guo, M.},
   title = {Thoracoscopic anatomic pulmonary segmentectomy: a 3-dimensional guided imaging system for lung operations},
   journal = {Interact Cardiovasc Thorac Surg},
   volume = {23},
   number = {2},
   pages = {183-9},
   note = {1569-9285
Yang, Qingjie
Xie, Baiyi
Hu, Meng
Sun, Xiaoyan
Huang, Xiaoyang
Guo, Ming
Journal Article
England
2016/04/22
Interact Cardiovasc Thorac Surg. 2016 Aug;23(2):183-9. doi: 10.1093/icvts/ivw085. Epub 2016 Apr 19.},
   abstract = {OBJECTIVES: To evaluate the Lung Operation Three-dimensional Imaging System software by Xiamen TRONG Technology Co. Ltd in detecting the precise position of solitary pulmonary nodules or ground-glass opacity nodules before surgery. METHODS: Chest, arterial phase, portal venous phase, enhanced and delayed-phase images of 10 cases with 12 nodules were obtained with a Toshiba Aquilion One 320 computed tomography (CT) scanner. According to the image data of the nodules, 0.5 mm thick images of 320-row multislice CT scanners were reconstructed as 3D images, and the boundary of each segment was automatically partitioned and pigmented in accordance with the pulmonary artery system. To locate the nodules, the 3D images and coloured segments were merged. The clearly labelled lung structure was utilized in a preoperative virtual segmentectomy and the subsequently planned thoracoscopic surgery. RESULTS: In all 10 cases, the reconstruction of the pulmonary artery could image branches as far as Grade 5. The anatomically adjacent relationship of the nodules among the arteries, veins and bronchi in the target pulmonary segments could be displayed in any view. The thoracoscopic anatomic pulmonary segmentectomy was performed successfully. All 12 nodules, which had deeply settled in the parenchyma, were resected using the virtual planning software and diagnosed pathologically. CONCLUSIONS: The software can be used preoperatively as a tracing method to identify the location of nodules in most general thoracic surgeries, subsequently providing guidance during the surgery.},
   keywords = {Equipment Design
Female
Humans
Imaging, Three-Dimensional/*instrumentation
Lung/*diagnostic imaging/surgery
Lung Neoplasms/*surgery
Male
Middle Aged
Pneumonectomy/*methods
Solitary Pulmonary Nodule/diagnosis/*surgery
Surgery, Computer-Assisted/*methods
Thoracoscopy/*methods
Ground-glass opacity
Segmentectomy
Solitary pulmonary nodule
Three-dimensional reconstruction imaging
Video-assisted thoracic surgery},
   ISSN = {1569-9285},
   DOI = {10.1093/icvts/ivw085},
   year = {2016},
   type = {Journal Article}
}

@article{RN57,
   author = {Hanaoka, S. and Masutani, Y. and Nemoto, M. and Nomura, Y. and Miki, S. and Yoshikawa, T. and Hayashi, N. and Ohtomo, K. and Shimizu, A.},
   title = {Landmark-guided diffeomorphic demons algorithm and its application to automatic segmentation of the whole spine and pelvis in CT images},
   journal = {Int J Comput Assist Radiol Surg},
   volume = {12},
   number = {3},
   pages = {413-430},
   note = {1861-6429
Hanaoka, Shouhei
Orcid: 0000-0002-7496-1651
Masutani, Yoshitaka
Nemoto, Mitsutaka
Nomura, Yukihiro
Miki, Soichiro
Yoshikawa, Takeharu
Hayashi, Naoto
Ohtomo, Kuni
Shimizu, Akinobu
Journal Article
Germany
2016/12/03
Int J Comput Assist Radiol Surg. 2017 Mar;12(3):413-430. doi: 10.1007/s11548-016-1507-z. Epub 2016 Nov 30.},
   abstract = {PURPOSE: A fully automatic multiatlas-based method for segmentation of the spine and pelvis in a torso CT volume is proposed. A novel landmark-guided diffeomorphic demons algorithm is used to register a given CT image to multiple atlas volumes. This algorithm can utilize both grayscale image information and given landmark coordinate information optimally. METHODS: The segmentation has four steps. Firstly, 170 bony landmarks are detected in the given volume. Using these landmark positions, an atlas selection procedure is performed to reduce the computational cost of the following registration. Then the chosen atlas volumes are registered to the given CT image. Finally, voxelwise label voting is performed to determine the final segmentation result. RESULTS: The proposed method was evaluated using 50 torso CT datasets as well as the public SpineWeb dataset. As a result, a mean distance error of [Formula: see text] and a mean Dice coefficient of [Formula: see text] were achieved for the whole spine and the pelvic bones, which are competitive with other state-of-the-art methods. CONCLUSION: From the experimental results, the usefulness of the proposed segmentation method was validated.},
   keywords = {*Algorithms
Anatomic Landmarks/*diagnostic imaging
Cone-Beam Computed Tomography
Humans
Imaging, Three-Dimensional/*methods
Pelvic Bones/*diagnostic imaging
Spine/*diagnostic imaging
Anatomical landmark
Diffeomorphic demons algorithm
Multiatlas segmentation
Pelvis
Spine},
   ISSN = {1861-6410},
   DOI = {10.1007/s11548-016-1507-z},
   year = {2017},
   type = {Journal Article}
}

@article{RN25,
   author = {Morley, L. and Cashell, A.},
   title = {Collaboration in Health Care},
   journal = {J Med Imaging Radiat Sci},
   volume = {48},
   number = {2},
   pages = {207-216},
   note = {1876-7982
Morley, Lyndon
Cashell, Angela
Journal Article
United States
2017/06/01
J Med Imaging Radiat Sci. 2017 Jun;48(2):207-216. doi: 10.1016/j.jmir.2017.02.071. Epub 2017 May 31.},
   abstract = {Health care involves the participation of patients, family, and a diverse team of often highly specialized health care professionals. Involvement of all these team members in a cooperative and coordinated way is essential to providing exceptional care. This article introduces key concepts relating to interprofessional collaborative teamwork. Approaches to measuring and studying collaboration and evidence demonstrating the benefits of collaboration are presented. The structural, psychological, and educational factors which may determine collaborative behaviour are described. LEARNING OBJECTIVES: By the end of this CME article, participants will be able to 1. Distinguish between multifunctional and interdisciplinary teams, 2. Define collaboration in a health care setting, 3. Describe the value of collaboration to patients, staff, and organizations, 4. Understand approaches to measuring collaboration, and 5. Identify factors that determine the ability of teams to collaborate. This article is a CME article and provides the equivalent of 2 hours of continuing education that may be applied to your professional development credit system. A 20-question multiple choice quiz follows this reading, and answers can be found on page 216. Please note that no formalized credit (Category A) is available from CAMRT.},
   keywords = {Collaboration
interdisciplinary
multidisciplinary
radiotherapy
teamwork},
   ISSN = {1876-7982},
   DOI = {10.1016/j.jmir.2017.02.071},
   year = {2017},
   type = {Journal Article}
}

@article{RN45,
   author = {Sampogna, G. and Pugliese, R. and Elli, M. and Vanzulli, A. and Forgione, A.},
   title = {Routine clinical application of virtual reality in abdominal surgery},
   journal = {Minim Invasive Ther Allied Technol},
   volume = {26},
   number = {3},
   pages = {135-143},
   note = {1365-2931
Sampogna, Gianluca
Pugliese, Raffaele
Elli, Marco
Vanzulli, Angelo
Forgione, Antonello
Journal Article
England
2017/01/14
Minim Invasive Ther Allied Technol. 2017 Jun;26(3):135-143. doi: 10.1080/13645706.2016.1275016. Epub 2017 Jan 13.},
   abstract = {BACKGROUND: The advantages of 3D reconstruction, immersive virtual reality (VR) and 3D printing in abdominal surgery have been enunciated for many years, but still today their application in routine clinical practice is almost nil. We investigate their feasibility, user appreciation and clinical impact. MATERIAL AND METHODS: Fifteen patients undergoing pancreatic, hepatic or renal surgery were studied realizing a 3D reconstruction of target anatomy. Then, an immersive VR environment was developed to import 3D models, and some details of the 3D scene were printed. All the phases of our workflow employed open-source software and low-cost hardware, easily implementable by other surgical services. A qualitative evaluation of the three approaches was performed by 20 surgeons, who filled in a specific questionnaire regarding a clinical case for each organ considered. RESULTS: Preoperative surgical planning and intraoperative guidance was feasible for all patients included in the study. The vast majority of surgeons interviewed scored their quality and usefulness as very good. CONCLUSIONS: Despite extra time, costs and efforts necessary to implement these systems, the benefits shown by the analysis of questionnaires recommend to invest more resources to train physicians to adopt these technologies routinely, even if further and larger studies are still mandatory.},
   keywords = {Feasibility Studies
Humans
Imaging, Three-Dimensional/*methods
Intraoperative Care/methods
Kidney/surgery
Liver/surgery
*Models, Anatomic
Pancreas/surgery
Preoperative Care/methods
*Printing, Three-Dimensional
Software
Surgeons
Surveys and Questionnaires
*Virtual Reality
Workflow
3D printing
3D reconstruction
Virtual reality
hepatobiliarypancreatic surgery
renal surgery},
   ISSN = {1364-5706},
   DOI = {10.1080/13645706.2016.1275016},
   year = {2017},
   type = {Journal Article}
}

@inproceedings{RN55,
   author = {Sarker, P. and Shuvo, M. M. H. and Hossain, Z. and Hasan, S.},
   title = {Segmentation and classification of lung tumor from 3D CT image using K-means clustering algorithm},
   booktitle = {2017 4th International Conference on Advances in Electrical Engineering (ICAEE)},
   pages = {731-736},
   ISBN = {2378-2692},
   DOI = {10.1109/ICAEE.2017.8255451},
   type = {Conference Proceedings}
}

@article{RN58,
   author = {Bahirat, Kanchan and Lai, Chengyuan and Mcmahan, Ryan P. and Prabhakaran, Balakrishnan},
   title = {Designing and Evaluating a Mesh Simplification Algorithm for Virtual Reality},
   journal = {ACM Trans. Multimedia Comput. Commun. Appl.},
   volume = {14},
   number = {3s},
   pages = {Article 63},
   keywords = {virtual reality, quadric error metric, Mesh simplification},
   ISSN = {1551-6857},
   DOI = {10.1145/3209661},
   url = {https://doi.org/10.1145/3209661},
   year = {2018},
   type = {Journal Article}
}

@article{RN61,
   author = {Blender, O},
   title = {Blender—A 3D modelling and rendering package},
   journal = {Retrieved. represents the sequence of Constructs1 to},
   volume = {4},
   year = {2018},
   type = {Journal Article}
}

@inproceedings{RN63,
   author = {Gugenheimer, J. and Stemasov, E. and Frommel, J. and Rukzio, E.},
   title = {A Demonstration of ShareVR: Co-Located Experiences for Virtual Reality Between HMD and Non-HMD Users},
   booktitle = {2018 IEEE Conference on Virtual Reality and 3D User Interfaces (VR)},
   pages = {755-756},
   DOI = {10.1109/VR.2018.8446551},
   type = {Conference Proceedings}
}

@article{RN48,
   author = {Le Moal, J. and Peillon, C. and Dacher, J. N. and Baste, J. M.},
   title = {Three-dimensional computed tomography reconstruction for operative planning in robotic segmentectomy: a pilot study},
   journal = {J Thorac Dis},
   volume = {10},
   number = {1},
   pages = {196-201},
   note = {2077-6624
Le Moal, Julien
Peillon, Christophe
Dacher, Jean-Nicolas
Baste, Jean-Marc
Journal Article
China
2018/03/31
J Thorac Dis. 2018 Jan;10(1):196-201. doi: 10.21037/jtd.2017.11.144.},
   abstract = {BACKGROUND: The objective of our pilot study was to assess if three-dimensional (3D) reconstruction performed by Visible Patient™ could be helpful for the operative planning, efficiency and safety of robot-assisted segmentectomy. METHODS: Between 2014 and 2015, 3D reconstructions were provided by the Visible Patient™ online service and used for the operative planning of robotic segmentectomy. To obtain 3D reconstruction, the surgeon uploaded the anonymized computed tomography (CT) image of the patient to the secured Visible Patient™ server and then downloaded the model after completion. RESULTS: Nine segmentectomies were performed between 2014 and 2015 using a pre-operative 3D model. All 3D reconstructions met our expectations: anatomical accuracy (bronchi, arteries, veins, tumor, and the thoracic wall with intercostal spaces), accurate delimitation of each segment in the lobe of interest, margin resection, free space rotation, portability (smartphone, tablet) and time saving technique. CONCLUSIONS: We have shown that operative planning by 3D CT using Visible Patient™ reconstruction is useful in our practice of robot-assisted segmentectomy. The main disadvantage is the high cost. Its impact on reducing complications and improving surgical efficiency is the object of an ongoing study.},
   keywords = {Robotic surgery
ground-glass nodules
lung cancer
segmentectomy
three-dimensional computed tomography (3D CT) reconstruction},
   ISSN = {2072-1439 (Print)
2072-1439},
   DOI = {10.21037/jtd.2017.11.144},
   year = {2018},
   type = {Journal Article}
}

@article{RN30,
   author = {Yiasemidou, M. and Glassman, D. and Jayne, D. and Miskovic, D.},
   title = {Is patient-specific pre-operative preparation feasible in a clinical environment? A systematic review and meta-analysis},
   journal = {Comput Assist Surg (Abingdon)},
   volume = {23},
   number = {1},
   pages = {57-68},
   note = {2469-9322
Yiasemidou, Marina
Glassman, Daniel
Jayne, David
Miskovic, Danilo
Journal Article
Meta-Analysis
Research Support, Non-U.S. Gov't
Systematic Review
England
2018/12/01
Comput Assist Surg (Abingdon). 2018 Dec;23(1):57-68. doi: 10.1080/24699322.2018.1495266.},
   abstract = {Technical difficulty of an operation is associated with patient and disease characteristics, indicating the necessity for surgeons to exercise patient-specific preparation. Such methods have been shown to be effective in the simulation suite, however, application in a real clinical environment has been sporadic. This systematic review attempts to answer if patient-specific preparation in challenging surgical procedures is feasible. A systematic review of OvidMedline, Embase and all Evidence Based Medicine review databases, was conducted in search of studies who described surgical rehearsals in all specialties. Following the application of defined inclusion and exclusion criteria relevant data were extracted and summarised. Descriptive synthesis was performed for all included studies and meta-analysis of data was applied when possible. Of fourty-nine studies included, thirty-seven were case-series, ten were non-randomised comparative trials and two randomised controlled trials. Accuracy of applied methods ranged from 66.7 to 100% and a good outcome was seen in 60-100% of operations. Meta-analysis of studies comparing rehearsals to real procedures (same patients) showed that simulated procedures were significantly faster than real ones (SMD = -1.56 [-2.19, -0.93] p < 0.00001) but were similar in other outcomes (fluoroscopy time: SMD = -0.1 [-0.63, 0.42] p = 0.7, fluoroscopy volume: SMD = -0.43[-0.97, 0.11], p = 0.12). Meta-analysis of studies comparing pre-operative rehearsals to standard treatment (two distinct groups of patients), demonstrated that real procedures were performed quicker if pre-operative rehearsal took place (SMD = -0.47 [-0.79, -0.16], P  = 0.003) but the immediate clinical outcome was similar for practiced and not practiced operations (SMD =0.03[-0.23, 0.29], p = 0.82). Current evidence suggests that patient-specific pre-operative preparation is feasible and safe and decreases operational time.},
   keywords = {Computer-Aided Design
Feasibility Studies
Humans
Image Processing, Computer-Assisted
Models, Anatomic
*Patient-Specific Modeling
Precision Medicine
Preoperative Care/*methods
Printing, Three-Dimensional
3D imaging
Patient-specific
simulation
surgical rehearsals},
   ISSN = {2469-9322},
   DOI = {10.1080/24699322.2018.1495266},
   year = {2018},
   type = {Journal Article}
}

@inproceedings{RN26,
   author = {Chheang, V. and Saalfeld, P. and Huber, T. and Huettl, F. and Kneist, W. and Preim, B. and Hansen, C.},
   title = {Collaborative Virtual Reality for Laparoscopic Liver Surgery Training},
   booktitle = {2019 IEEE International Conference on Artificial Intelligence and Virtual Reality (AIVR)},
   pages = {1-17},
   DOI = {10.1109/AIVR46125.2019.00011},
   type = {Conference Proceedings}
}

@article{RN50,
   author = {Lenchik, L. and Heacock, L. and Weaver, A. A. and Boutin, R. D. and Cook, T. S. and Itri, J. and Filippi, C. G. and Gullapalli, R. P. and Lee, J. and Zagurovskaya, M. and Retson, T. and Godwin, K. and Nicholson, J. and Narayana, P. A.},
   title = {Automated Segmentation of Tissues Using CT and MRI: A Systematic Review},
   journal = {Acad Radiol},
   volume = {26},
   number = {12},
   pages = {1695-1706},
   note = {1878-4046
Lenchik, Leon
Heacock, Laura
Weaver, Ashley A
Boutin, Robert D
Cook, Tessa S
Itri, Jason
Filippi, Christopher G
Gullapalli, Rao P
Lee, James
Zagurovskaya, Marianna
Retson, Tara
Godwin, Kendra
Nicholson, Joey
Narayana, Ponnada A
K25 AG058804/AG/NIA NIH HHS/United States
P30 AG021332/AG/NIA NIH HHS/United States
Journal Article
Research Support, N.I.H., Extramural
Systematic Review
United States
2019/08/14
Acad Radiol. 2019 Dec;26(12):1695-1706. doi: 10.1016/j.acra.2019.07.006. Epub 2019 Aug 10.},
   abstract = {RATIONALE AND OBJECTIVES: The automated segmentation of organs and tissues throughout the body using computed tomography and magnetic resonance imaging has been rapidly increasing. Research into many medical conditions has benefited greatly from these approaches by allowing the development of more rapid and reproducible quantitative imaging markers. These markers have been used to help diagnose disease, determine prognosis, select patients for therapy, and follow responses to therapy. Because some of these tools are now transitioning from research environments to clinical practice, it is important for radiologists to become familiar with various methods used for automated segmentation. MATERIALS AND METHODS: The Radiology Research Alliance of the Association of University Radiologists convened an Automated Segmentation Task Force to conduct a systematic review of the peer-reviewed literature on this topic. RESULTS: The systematic review presented here includes 408 studies and discusses various approaches to automated segmentation using computed tomography and magnetic resonance imaging for neurologic, thoracic, abdominal, musculoskeletal, and breast imaging applications. CONCLUSION: These insights should help prepare radiologists to better evaluate automated segmentation tools and apply them not only to research, but eventually to clinical practice.},
   keywords = {*Algorithms
Automation
Humans
Magnetic Resonance Imaging/*methods
Tomography, X-Ray Computed/*methods
Ct
Mri
Machine learning
Quantitative imaging
Segmentation},
   ISSN = {1076-6332 (Print)
1076-6332},
   DOI = {10.1016/j.acra.2019.07.006},
   year = {2019},
   type = {Journal Article}
}

@article{RN42,
   author = {Sardari Nia, P. and Olsthoorn, J. R. and Heuts, S. and Maessen, J. G.},
   title = {Interactive 3D Reconstruction of Pulmonary Anatomy for Preoperative Planning, Virtual Simulation, and Intraoperative Guiding in Video-Assisted Thoracoscopic Lung Surgery},
   journal = {Innovations (Phila)},
   volume = {14},
   number = {1},
   pages = {17-26},
   note = {1559-0879
Sardari Nia, Peyman
Olsthoorn, Jules R
Heuts, Samuel
Maessen, Jos G
Journal Article
United States
2019/03/09
Innovations (Phila). 2019 Feb;14(1):17-26. doi: 10.1177/1556984519826321. Epub 2019 Feb 20.},
   abstract = {OBJECTIVES: Routine imaging modalities combined with state-of-the-art reconstruction software can substantially improve preoperative planning and simplify complex procedure by enhancing the surgeon's knowledge of the patient's specific anatomy. The aim of the current study was to demonstrate the feasibility of interactive three-dimensional (3D) computed tomography (CT) reconstructions for preoperative planning and intraoperative guiding in video-assisted thoracoscopic lung surgery (VATS) with 3D vision. METHODS: Twenty-five consecutive patients referred for an anatomic pulmonary resection by a single surgeon were included. Data were collected prospectively. All patients underwent a CT angiography in the diagnostic pathway prior to referral. 3D reconstruction of the pulmonary anatomy was obtained from CT scans with dedicated software. An interactive PDF file of the 3D reconstruction with virtual resection was created, in which all the pulmonary structures could be individually selected. Furthermore, the reconstructions were used for intraoperative guiding on double monitor during VATS with 3D vision. RESULTS: In total, 26 procedures were performed for 5 benign and 21 malignant conditions. Lobectomy and segmentectomy were performed in 20 (76.9 %) and 6 (23.1%) cases, respectively. In all patients, preoperative 3D reconstruction of pulmonary vessels corresponded with the intraoperative findings. Reconstructions revealed anatomic variations in 4 (15.4%) patients. No conversion to thoracotomy or in-hospital mortality occurred. CONCLUSIONS: Preoperative planning with interactive 3D CT reconstruction is a useful method to enhance the surgeon's knowledge of the patient's specific anatomy and to reveal anatomic variations. Intraoperative 3D guiding in VATS with 3D vision is feasible and could contribute to the safety and accuracy of anatomic resection.},
   keywords = {Aged
Computed Tomography Angiography/methods
Feasibility Studies
Female
Humans
Imaging, Three-Dimensional/*methods
Intraoperative Period
Lung/*anatomy & histology/blood supply/pathology/*surgery
Male
Middle Aged
Pneumonectomy/methods
Postoperative Complications/epidemiology
Preoperative Period
Prospective Studies
Surgeons/education
Thoracic Surgery, Video-Assisted/*methods
3D reconstruction
intraoperative guiding
lung surgery
preoperative planning
video-assisted thoracoscopic surgery (VATS)},
   ISSN = {1556-9845},
   DOI = {10.1177/1556984519826321},
   year = {2019},
   type = {Journal Article}
}

@article{RN34,
   author = {Shirk, J. D. and Kwan, L. and Saigal, C.},
   title = {The Use of 3-Dimensional, Virtual Reality Models for Surgical Planning of Robotic Partial Nephrectomy},
   journal = {Urology},
   volume = {125},
   pages = {92-97},
   note = {1527-9995
Shirk, Joseph D
Kwan, Lorna
Saigal, Christopher
Comparative Study
Journal Article
Research Support, Non-U.S. Gov't
United States
2019/01/01
Urology. 2019 Mar;125:92-97. doi: 10.1016/j.urology.2018.12.026. Epub 2018 Dec 28.},
   abstract = {OBJECTIVE: To determine whether 3-dimensional virtual reality models of patient-specific anatomy improve outcomes in patients undergoing robotic partial nephrectomy. MATERIALS AND METHODS: Computed tomography and magnetic resonance imaging scans for 30 patients undergoing robotic partial nephrectomy were converted to 3-dimensional virtual reality models prior to the patient's operation. These models were then viewed on the surgeon's mobile phone pre- and intraoperatively using a Google Cardboard headset to assist in surgical planning. This group was compared to 30 patients who previously underwent robotic partial nephrectomy. We compared operative time, clamp time, estimated blood loss, hospital stay, complications, and margin status between these groups. We used forward selecting multivariate regression models to create the final model controlling for significant demographic and clinical variables. RESULTS: When controlling for case complexity and surgeon, patients with 3-dimensional, virtual reality-assisted surgical planning had significantly lower operative time (141 minutes vs 201 minutes, P < .0001), clamp time (13.2 minutes vs 17.4 minutes, P = .0274), and estimated blood loss (134 cc vs 259 cc, P = .0233). Patients without 3-dimensional, virtual reality-assisted surgical planning were more likely to have a hospital stay of greater than 2 days (odds ratio 5.1, 95% confidence interval 1.0, 26.4). There were no complications or positive margins noted in the VR group. CONCLUSION: Use of a 3-dimensional, virtual reality model when performing robotic partial nephrectomy improves key surgical outcome parameters.},
   keywords = {Computer Simulation
Female
Humans
*Imaging, Three-Dimensional
Kidney/*diagnostic imaging
Magnetic Resonance Imaging
Male
Middle Aged
Nephrectomy/*methods
*Patient Care Planning
Robotic Surgical Procedures/*methods
Tomography, X-Ray Computed
*Virtual Reality},
   ISSN = {0090-4295},
   DOI = {10.1016/j.urology.2018.12.026},
   year = {2019},
   type = {Journal Article}
}

@article{RN36,
   author = {Shirk, J. D. and Thiel, D. D. and Wallen, E. M. and Linehan, J. M. and White, W. M. and Badani, K. K. and Porter, J. R.},
   title = {Effect of 3-Dimensional Virtual Reality Models for Surgical Planning of Robotic-Assisted Partial Nephrectomy on Surgical Outcomes: A Randomized Clinical Trial},
   journal = {JAMA Netw Open},
   volume = {2},
   number = {9},
   pages = {e1911598},
   note = {2574-3805
Shirk, Joseph D
Thiel, David D
Wallen, Eric M
Linehan, Jennifer M
White, Wesley M
Badani, Ketan K
Porter, James R
Journal Article
Randomized Controlled Trial
Research Support, Non-U.S. Gov't
United States
2019/09/19
JAMA Netw Open. 2019 Sep 4;2(9):e1911598. doi: 10.1001/jamanetworkopen.2019.11598.},
   abstract = {IMPORTANCE: Planning complex operations such as robotic-assisted partial nephrectomy requires surgeons to review 2-dimensional computed tomography or magnetic resonance images to understand 3-dimensional (3-D), patient-specific anatomy. OBJECTIVE: To determine surgical outcomes for robotic-assisted partial nephrectomy when surgeons reviewed 3-D virtual reality (VR) models during operative planning. DESIGN, SETTING, AND PARTICIPANTS: A single-blind randomized clinical trial was performed. Ninety-two patients undergoing robotic-assisted partial nephrectomy performed by 1 of 11 surgeons at 6 large teaching hospitals were prospectively enrolled and randomized. Enrollment and data collection occurred from October 2017 through December 2018, and data analysis was performed from December 2018 through March 2019. INTERVENTIONS: Patients were assigned to either a control group undergoing usual preoperative planning with computed tomography and/or magnetic resonance imaging only or an intervention group where imaging was supplemented with a 3-D VR model. This model was viewed on the surgeon's smartphone in regular 3-D format and in VR using a VR headset. MAIN OUTCOMES AND MEASURES: The primary outcome measure was operative time. It was hypothesized that the operations performed using the 3-D VR models would have shorter operative time than those performed without the models. Secondary outcomes included clamp time, estimated blood loss, and length of hospital stay. RESULTS: Ninety-two patients (58 men [63%]) with a mean (SD) age of 60.9 (11.6) years were analyzed. The analysis included 48 patients randomized to the control group and 44 randomized to the intervention group. When controlling for case complexity and other covariates, patients whose surgical planning involved 3-D VR models showed differences in operative time (odds ratio [OR], 1.00; 95% CI, 0.37-2.70; estimated OR, 2.47), estimated blood loss (OR, 1.98; 95% CI, 1.04-3.78; estimated OR, 4.56), clamp time (OR, 1.60; 95% CI, 0.79-3.23; estimated OR, 11.22), and length of hospital stay (OR, 2.86; 95% CI, 1.59-5.14; estimated OR, 5.43). Estimated ORs were calculated using the parameter estimates from the generalized estimating equation model. Referent group values for each covariate and the corresponding nephrometry score were summed across the covariates and nephrometry score, and the sum was exponentiated to obtain the OR. A mean of the estimated OR weighted by sample size for each nephrometry score strata was then calculated. CONCLUSIONS AND RELEVANCE: This large, randomized clinical trial demonstrated that patients whose surgical planning involved 3-D VR models had reduced operative time, estimated blood loss, clamp time, and length of hospital stay. TRIAL REGISTRATION: ClinicalTrials.gov identifiers (1 registration per site): NCT03334344, NCT03421418, NCT03534206, NCT03542565, NCT03556943, and NCT03666104.},
   keywords = {Blood Loss, Surgical/statistics & numerical data
*Computer Simulation
Female
Glomerular Filtration Rate
Humans
*Imaging, Three-Dimensional
Length of Stay/*statistics & numerical data
Male
Middle Aged
Nephrectomy/*instrumentation/methods
Operative Time
*Robotic Surgical Procedures
Single-Blind Method
Virtual Reality},
   ISSN = {2574-3805},
   DOI = {10.1001/jamanetworkopen.2019.11598},
   year = {2019},
   type = {Journal Article}
}

@article{RN65,
   author = {Chheang, Vuthea and Fischer, Virve and Buggenhagen, Holger and Huber, Tobias and Huettl, Florentine and Kneist, Werner and Preim, Bernhard and Saalfeld, Patrick and Hansen, Christian},
   title = {Toward interprofessional team training for surgeons and anesthesiologists using virtual reality},
   journal = {International Journal of Computer Assisted Radiology and Surgery},
   volume = {15},
   number = {12},
   pages = {2109-2118},
   abstract = {In this work, a virtual environment for interprofessional team training in laparoscopic surgery is proposed. Our objective is to provide a tool to train and improve intraoperative communication between anesthesiologists and surgeons during laparoscopic procedures.},
   ISSN = {1861-6429},
   DOI = {10.1007/s11548-020-02276-y},
   url = {https://doi.org/10.1007/s11548-020-02276-y},
   year = {2020},
   type = {Journal Article}
}

@article{RN33,
   author = {Rahman, R. and Wood, M. E. and Qian, L. and Price, C. L. and Johnson, A. A. and Osgood, G. M.},
   title = {Head-Mounted Display Use in Surgery: A Systematic Review},
   journal = {Surg Innov},
   volume = {27},
   number = {1},
   pages = {88-100},
   note = {1553-3514
Rahman, Rafa
Wood, Matthew E
Qian, Long
Price, Carrie L
Johnson, Alex A
Osgood, Greg M
Orcid: 0000-0001-6271-4971
Journal Article
Systematic Review
United States
2019/09/14
Surg Innov. 2020 Feb;27(1):88-100. doi: 10.1177/1553350619871787. Epub 2019 Sep 12.},
   abstract = {Purpose. We analyzed the literature to determine (1) the surgically relevant applications for which head-mounted display (HMD) use is reported; (2) the types of HMD most commonly reported; and (3) the surgical specialties in which HMD use is reported. Methods. The PubMed, Embase, Cochrane Library, and Web of Science databases were searched through August 27, 2017, for publications describing HMD use during surgically relevant applications. We identified 120 relevant English-language, non-opinion publications for inclusion. HMD types were categorized as "heads-up" (nontransparent HMD display and direct visualization of the real environment), "see-through" (visualization of the HMD display overlaid on the real environment), or "non-see-through" (visualization of only the nontransparent HMD display). Results. HMDs were used for image guidance and augmented reality (70 publications), data display (63 publications), communication (34 publications), and education/training (18 publications). See-through HMDs were described in 55 publications, heads-up HMDs in 41 publications, and non-see-through HMDs in 27 publications. Google Glass, a see-through HMD, was the most frequently used model, reported in 32 publications. The specialties with the highest frequency of published HMD use were urology (20 publications), neurosurgery (17 publications), and unspecified surgical specialty (20 publications). Conclusion. Image guidance and augmented reality were the most commonly reported applications for which HMDs were used. See-through HMDs were the most commonly reported type used in surgically relevant applications. Urology and neurosurgery were the specialties with greatest published HMD use.},
   keywords = {*Augmented Reality
Equipment Design
Fluoroscopy/instrumentation
Humans
*Surgery, Computer-Assisted/instrumentation/methods
*Virtual Reality
augmented reality
head-mounted display
virtual reality},
   ISSN = {1553-3506},
   DOI = {10.1177/1553350619871787},
   year = {2020},
   type = {Journal Article}
}

@article{RN37,
   author = {Sadeghi, A. H. and Bakhuis, W. and Van Schaagen, F. and Oei, F. B. S. and Bekkers, J. A. and Maat, Apwm and Mahtab, E. A. F. and Bogers, Ajjc and Taverne, Yjhj},
   title = {Immersive 3D virtual reality imaging in planning minimally invasive and complex adult cardiac surgery},
   journal = {Eur Heart J Digit Health},
   volume = {1},
   number = {1},
   pages = {62-70},
   note = {2634-3916
Sadeghi, Amir H
Orcid: 0000-0002-6118-2341
Bakhuis, Wouter
Van Schaagen, Frank
Oei, Frans B S
Bekkers, Jos A
Maat, Alexander P W M
Mahtab, Edris A F
Bogers, Ad J J C
Taverne, Yannick J H J
Journal Article
England
2020/11/23
Eur Heart J Digit Health. 2020 Nov 23;1(1):62-70. doi: 10.1093/ehjdh/ztaa011. eCollection 2020 Nov.},
   abstract = {AIMS: Increased complexity in cardiac surgery over the last decades necessitates more precise preoperative planning to minimize operating time, to limit the risk of complications during surgery and to aim for the best possible patient outcome. Novel, more realistic, and more immersive techniques, such as three-dimensional (3D) virtual reality (VR) could potentially contribute to the preoperative planning phase. This study shows our initial experience on the implementation of immersive VR technology as a complementary research-based imaging tool for preoperative planning in cardiothoracic surgery. In addition, essentials to set up and implement a VR platform are described. METHODS: Six patients who underwent cardiac surgery at the Erasmus Medical Center, Rotterdam, The Netherlands, between March 2020 and August 2020, were included, based on request by the surgeon and availability of computed tomography images. After 3D VR rendering and 3D segmentation of specific structures, the reconstruction was analysed via a head mount display. All participating surgeons (n = 5) filled out a questionnaire to evaluate the use of VR as preoperative planning tool for surgery. CONCLUSION: Our study demonstrates that immersive 3D VR visualization of anatomy might be beneficial as a supplementary preoperative planning tool for cardiothoracic surgery, and further research on this topic may be considered to implement this innovative tool in daily clinical practice. LAY SUMMARY: Over the past decades, surgery on the heart and vessels is becoming more and more complex, necessitating more precise and accurate preoperative planning. Nowadays, operative planning is feasible on flat, two-dimensional computer screens, however, requiring a lot of spatial and three-dimensional (3D) thinking of the surgeon. Since immersive 3D virtual reality (VR) is an upcoming imaging technique with promising results in other fields of surgery, we aimed in this study to explore the additional value of this technique in heart surgery. Our surgeons planned six different heart operations by visualizing computed tomography scans with a dedicated VR headset, enabling them to visualize the patient's anatomy in an immersive and 3D environment. The outcomes of this preliminary study are positive, with a much more reality-like simulation for the surgeon. In such, VR could potentially be beneficial as a preoperative planning tool for complex heart surgery.},
   keywords = {Cardiothoracic surgery
Innovation
Minimally invasive cardiac surgery
Preoperative planning
Virtual reality},
   ISSN = {2634-3916},
   DOI = {10.1093/ehjdh/ztaa011},
   year = {2020},
   type = {Journal Article}
}

@article{RN29,
   author = {Zawy Alsofy, S. and Sakellaropoulou, I. and Stroop, R.},
   title = {Evaluation of Surgical Approaches for Tumor Resection in the Deep Infratentorial Region and Impact of Virtual Reality Technique for the Surgical Planning and Strategy},
   journal = {J Craniofac Surg},
   volume = {31},
   number = {7},
   pages = {1865-1869},
   note = {1536-3732
Zawy Alsofy, Samer
Sakellaropoulou, Ioanna
Stroop, Ralf
Evaluation Study
Journal Article
United States
2020/05/21
J Craniofac Surg. 2020 Oct;31(7):1865-1869. doi: 10.1097/SCS.0000000000006525.},
   abstract = {OBJECTIVE: Tumors in the deep infratentorial region can be accessed via the supracerebellar-infratentorial (SCIT) or suboccipital-transcerebellar (SOTC) approaches in the sitting or prone position. Diagnosis of tumors in this region and review of their therapies are inseparably connected with cranial tomographic imaging. We retrospectively evaluate a cohort of patients who underwent tumor resection in this region and correlate complication rates to the literature, and evaluate the potential influence of a virtual reality (VR) visualization technique on surgery planning and strategy. METHODS: Patient files were retrospectively analyzed regarding operative performance parameters, histopathological findings, surgical outcomes, and complications. Preoperative magnetic resonance imaging scans were visualized via VR software. The influence of 3-dimensional VR images compared to 2-dimensional magnetic resonance imaging scans on surgical planning and surgical strategy was evaluated using a questionnaire. RESULTS: Ninety-three patients were included, 80% placed in a sitting and 20% in a prone position. The SCIT approach was performed in 59% patients and SOTC approach in 41%. Surgical tumor resections were associated with an overall complication rate comparable to the literature. Image presentation using VR had a significant influence on the recommended surgical approach (P = 0.02), but no influence on the recommended patient positioning (P = 0.37) or placement of craniotomy (P = 0.09). CONCLUSION: Tumor resection in the deep infratentorial region, despite frequent use of the sitting position and SCIT approach, was associated with a complication rate comparable to the literature. Preoperative surgical planning using VR technology may increase understanding of the anatomy and pathology, and thus influence operation planning.},
   keywords = {Adult
Aged
Brain Neoplasms/*surgery
*Craniotomy/methods
Female
Humans
Imaging, Three-Dimensional
Male
Middle Aged
*Neurosurgical Procedures/methods
Retrospective Studies
*Virtual Reality
Young Adult},
   ISSN = {1049-2275},
   DOI = {10.1097/scs.0000000000006525},
   year = {2020},
   type = {Journal Article}
}

@article{RN6,
   author = {Chheang, Vuthea and Saalfeld, Patrick and Joeres, Fabian and Boedecker, Christian and Huber, Tobias and Huettl, Florentine and Lang, Hauke and Preim, Bernhard and Hansen, Christian},
   title = {A collaborative virtual reality environment for liver surgery planning},
   journal = {Computers and Graphics},
   volume = {99},
   pages = {234-246},
   abstract = {Surgical planning software is a key component in the treatment of tumor diseases. However, desktop-based systems provide only limited visualization and interaction opportunities. Moreover, collaborative planning among members of a surgical team is only possible to a limited extent. In this work, a collaborative virtual reality (VR) environment to assist liver surgeons in tumor surgery planning is presented. Our aim is to improve virtual resection planning between surgeons in a remote or co-located environment. The system allows surgeons to define and adjust virtual resections on patient-specific organ 3D surfaces and 2D image slices. Changes on both modalities are synchronized, which will enable surgeons to iterate and refine the resection surfaces quickly. In addition, a real-time risk map visualization is presented that displays safety margins around tumors. An evaluation performed by liver surgeons provides information on potential benefits, such as the possibility to visualize complex cases and assessing the safety-critical areas, applicability, and limitations for further improvement.},
   keywords = {Virtual reality
Surgical planning
Medical visualization
Human-computer interaction},
   ISSN = {0097-8493},
   DOI = {https://doi.org/10.1016/j.cag.2021.07.009},
   url = {https://www.sciencedirect.com/science/article/pii/S0097849321001400},
   year = {2021},
   type = {Journal Article}
}

@article{RN11,
   author = {Deng, S. and Wheeler, G. and Toussaint, N. and Munroe, L. and Bhattacharya, S. and Sajith, G. and Lin, E. and Singh, E. and Chu, K. Y. K. and Kabir, S. and Pushparajah, K. and Simpson, J. M. and Schnabel, J. A. and Gomez, A.},
   title = {A Virtual Reality System for Improved Image-Based Planning of Complex Cardiac Procedures},
   journal = {J Imaging},
   volume = {7},
   number = {8},
   note = {2313-433x
Deng, Shujie
Orcid: 0000-0001-9985-2374
Wheeler, Gavin
Toussaint, Nicolas
Munroe, Lindsay
Bhattacharya, Suryava
Sajith, Gina
Lin, Ei
Singh, Eeshar
Chu, Ka Yee Kelly
Kabir, Saleha
Pushparajah, Kuberan
Simpson, John M
Schnabel, Julia A
Gomez, Alberto
Orcid: 0000-0002-7897-7589
TA/F/20/210021/BHF_/British Heart Foundation/United Kingdom
Journal Article
Switzerland
2021/08/31
J Imaging. 2021 Aug 19;7(8):151. doi: 10.3390/jimaging7080151.},
   abstract = {The intricate nature of congenital heart disease requires understanding of the complex, patient-specific three-dimensional dynamic anatomy of the heart, from imaging data such as three-dimensional echocardiography for successful outcomes from surgical and interventional procedures. Conventional clinical systems use flat screens, and therefore, display remains two-dimensional, which undermines the full understanding of the three-dimensional dynamic data. Additionally, the control of three-dimensional visualisation with two-dimensional tools is often difficult, so used only by imaging specialists. In this paper, we describe a virtual reality system for immersive surgery planning using dynamic three-dimensional echocardiography, which enables fast prototyping for visualisation such as volume rendering, multiplanar reformatting, flow visualisation and advanced interaction such as three-dimensional cropping, windowing, measurement, haptic feedback, automatic image orientation and multiuser interactions. The available features were evaluated by imaging and nonimaging clinicians, showing that the virtual reality system can help improve the understanding and communication of three-dimensional echocardiography imaging and potentially benefit congenital heart disease treatment.},
   keywords = {echocardiography
pre-operative imaging
virtual reality},
   ISSN = {2313-433x},
   DOI = {10.3390/jimaging7080151},
   year = {2021},
   type = {Journal Article}
}

@article{RN60,
   author = {Farook, Taseef Hasan and Barman, Aparna and Abdullah, Johari Yap and Jamayet, Nafij Bin},
   title = {Optimization of Prosthodontic Computer-Aided Designed Models: A Virtual Evaluation of Mesh Quality Reduction Using Open Source Software},
   journal = {Journal of Prosthodontics},
   volume = {30},
   number = {5},
   pages = {420-429},
   abstract = {Abstract Purpose Mesh optimization reduces the texture quality of 3D models in order to reduce storage file size and computational load on a personal computer. This study aims to explore mesh optimization using open source (free) software in the context of prosthodontic application. Materials and Methods An auricular prosthesis, a complete denture, and anterior and posterior crowns were constructed using conventional methods and laser scanned to create computerized 3D meshes. The meshes were optimized independently by four computer-aided design software (Meshmixer, Meshlab, Blender, and SculptGL) to 100%, 90%, 75%, 50%, and 25% levels of original file size. Upon optimization, the following parameters were virtually evaluated and compared; mesh vertices, file size, mesh surface area (SA), mesh volume (V), interpoint discrepancies (geometric similarity based on virtual point overlapping), and spatial similarity (volumetric similarity based on shape overlapping). The influence of software and optimization on surface area and volume of each prosthesis was evaluated independently using multiple linear regression. Results There were clear observable differences in vertices, file size, surface area, and volume. The choice of software significantly influenced the overall virtual parameters of auricular prosthesis [SA: F(4,15) = 12.93, R2 = 0.67, p < 0.001. V: F(4,15) = 9.33, R2 = 0.64, p < 0.001] and complete denture [SA: F(4,15) = 10.81, R2 = 0.67, p < 0.001. V: F(4,15) = 3.50, R2 = 0.34, p = 0.030] across optimization levels. Interpoint discrepancies were however limited to <0.1mm and volumetric similarity was >97%. Conclusion Open-source mesh optimization of smaller dental prostheses in this study produced minimal loss of geometric and volumetric details. SculptGL models were most influenced by the amount of optimization performed.},
   ISSN = {1059-941X},
   DOI = {https://doi.org/10.1111/jopr.13286},
   url = {https://onlinelibrary.wiley.com/doi/abs/10.1111/jopr.13286},
   year = {2021},
   type = {Journal Article}
}

@article{RN49,
   author = {Louis, R. G. and Steinberg, G. K. and Duma, C. and Britz, G. and Mehta, V. and Pace, J. and Selman, W. and Jean, W. C.},
   title = {Early Experience With Virtual and Synchronized Augmented Reality Platform for Preoperative Planning and Intraoperative Navigation: A Case Series},
   journal = {Oper Neurosurg (Hagerstown)},
   volume = {21},
   number = {4},
   pages = {189-196},
   note = {2332-4260
Louis, Robert G
Steinberg, Gary K
Duma, Christopher
Britz, Gavin
Mehta, Vivek
Pace, Jonathan
Selman, Warren
Jean, Walter C
Orcid: 0000-0001-6774-2066
Journal Article
United States
2021/06/26
Oper Neurosurg (Hagerstown). 2021 Sep 15;21(4):189-196. doi: 10.1093/ons/opab188.},
   abstract = {BACKGROUND: Virtual reality (VR) allows for presurgical planning. Intraoperatively, augmented reality (AR) enables integration of segmented anatomic information with neuronavigation into the microsurgical scene to provide guidance without workflow disruption. Combining VR and AR solutions may help guide microsurgical technique to improve safety, efficiency, and ergonomics. OBJECTIVE: To describe a VR/AR platform that provides VR planning and intraoperative guidance via microscope ocular injection of a comprehensive AR overlay of patient-specific 360°/3D anatomic model aligned and synchronized with neuronavigation. METHODS: Custom 360° models from preoperative imaging of 49 patients were utilized for preoperative planning using a VR-based surgical rehearsal platform. Each model was imported to SyncAR, the platform's intraoperative counterpart, which was coregistered with Medtronic StealthStation S8 and Zeiss or Leica microscope. The model was injected into the microscope oculars and referenced throughout by adjusting overlay opacity. For anatomic shifts or misalignment, the overlay was reregistered via manual realignment with known landmarks. RESULTS: No SyncAR-related complications occurred. SyncAR contributed positively to the 3D understanding of patient-specific anatomy and ability to operate. Preoperative planning and intraoperative AR with 360° models allowed for more precise craniotomy planning and execution. SyncAR was useful for guiding dissection, identifying critical structures including hidden anatomy, understanding regional anatomy, and facilitating resection. Manual realignment was performed in 48/49 surgeries. Gross total resection was achieved in 34/40 surgeries. All aneurysm clipping and microvascular decompression procedures were completed without complications. CONCLUSION: SyncAR combined with VR planning has potential to enhance surgical performance by providing critical information in a user-friendly, continuously available, heads-up display format.},
   keywords = {*Augmented Reality
Humans
Models, Anatomic
Neuronavigation
*Virtual Reality
Augmented reality
Craniotomy
Microscopic surgery
Navigation
Surgical planning
Virtual reality},
   ISSN = {2332-4252 (Print)
2332-4252},
   DOI = {10.1093/ons/opab188},
   year = {2021},
   type = {Journal Article}
}

@article{RN31,
   author = {Mao, R. Q. and Lan, L. and Kay, J. and Lohre, R. and Ayeni, O. R. and Goel, D. P. and Sa, D.},
   title = {Immersive Virtual Reality for Surgical Training: A Systematic Review},
   journal = {J Surg Res},
   volume = {268},
   pages = {40-58},
   note = {1095-8673
Mao, Randi Q
Lan, Lucy
Kay, Jeffrey
Lohre, Ryan
Ayeni, Olufemi R
Goel, Danny P
Sa, Darren de
Journal Article
Review
Systematic Review
United States
2021/07/21
J Surg Res. 2021 Dec;268:40-58. doi: 10.1016/j.jss.2021.06.045. Epub 2021 Jul 17.},
   abstract = {BACKGROUND: Immersive virtual reality (iVR) simulators provide accessible, low cost, realistic training adjuncts in time and financially constrained systems. With increasing evidence and utilization of this technology by training programs, clarity on the effect of global skill training should be provided. This systematic review examines the current literature on the effectiveness of iVR for surgical skills acquisition in medical students, residents, and staff surgeons. METHODS: A literature search was performed on MEDLINE, EMBASE, CENTRAL, Web of Science and PsycInfo for primary studies published between January 1, 2000 and January 26, 2021. Two reviewers independently screened titles, abstracts, and full texts, extracted data, and assessed quality and strength of evidence using the Medical Education Research Quality Instrument (MERSQI) and Cochrane methodology. Results were qualitatively synthesized, and descriptive statistics were calculated. RESULTS: The literature search yielded 9650 citations, with 17 articles included for qualitative synthesis. The mean (SD) MERSQI score was 11.7 (1.9) out of 18. In total, 307 participants completed training in four disciplines. Immersive VR-trained groups performed 18% to 43% faster on procedural time to completion compared to control (pooled standardized mean difference = -0.90 [95% CI=-1.33 to -047, I(2)=1%, P < 0.0001]). Immersive VR trainees also demonstrated greater post-intervention scores on procedural checklists and greater implant placement accuracy compared to control. CONCLUSIONS: Immersive VR incorporation into surgical training programs is supported by high-quality, albeit heterogeneous, studies demonstrating improved procedural times, task completion, and accuracy, positive user ratings, and cost-effectiveness.},
   keywords = {Clinical Competence
Humans
*Internship and Residency
*Simulation Training/methods
*Students, Medical
*Virtual Reality
Competency-based education
Medical education
Simulation training
Surgery
Surgical education
Virtual reality},
   ISSN = {0022-4804},
   DOI = {10.1016/j.jss.2021.06.045},
   year = {2021},
   type = {Journal Article}
}

@article{RN54,
   author = {Ranjbarzadeh, Ramin and Bagherian Kasgari, Abbas and Jafarzadeh Ghoushchi, Saeid and Anari, Shokofeh and Naseri, Maryam and Bendechache, Malika},
   title = {Brain tumor segmentation based on deep learning and an attention mechanism using MRI multi-modalities brain images},
   journal = {Scientific Reports},
   volume = {11},
   number = {1},
   pages = {10930},
   abstract = {Brain tumor localization and segmentation from magnetic resonance imaging (MRI) are hard and important tasks for several applications in the field of medical analysis. As each brain imaging modality gives unique and key details related to each part of the tumor, many recent approaches used four modalities T1, T1c, T2, and FLAIR. Although many of them obtained a promising segmentation result on the BRATS 2018 dataset, they suffer from a complex structure that needs more time to train and test. So, in this paper, to obtain a flexible and effective brain tumor segmentation system, first, we propose a preprocessing approach to work only on a small part of the image rather than the whole part of the image. This method leads to a decrease in computing time and overcomes the overfitting problems in a Cascade Deep Learning model. In the second step, as we are dealing with a smaller part of brain images in each slice, a simple and efficient Cascade Convolutional Neural Network (C-ConvNet/C-CNN) is proposed. This C-CNN model mines both local and global features in two different routes. Also, to improve the brain tumor segmentation accuracy compared with the state-of-the-art models, a novel Distance-Wise Attention (DWA) mechanism is introduced. The DWA mechanism considers the effect of the center location of the tumor and the brain inside the model. Comprehensive experiments are conducted on the BRATS 2018 dataset and show that the proposed model obtains competitive results: the proposed method achieves a mean whole tumor, enhancing tumor, and tumor core dice scores of 0.9203, 0.9113 and 0.8726 respectively. Other quantitative and qualitative assessments are presented and discussed.},
   ISSN = {2045-2322},
   DOI = {10.1038/s41598-021-90428-8},
   url = {https://doi.org/10.1038/s41598-021-90428-8},
   year = {2021},
   type = {Journal Article}
}

@article{RN10,
   author = {Sadeghi, A. H. and Maat, Apwm and Taverne, Yjhj and Cornelissen, R. and Dingemans, A. C. and Bogers, Ajjc and Mahtab, E. A. F.},
   title = {Virtual reality and artificial intelligence for 3-dimensional planning of lung segmentectomies},
   journal = {JTCVS Tech},
   volume = {7},
   pages = {309-321},
   note = {2666-2507
Sadeghi, Amir H
Maat, Alexander P W M
Taverne, Yannick J H J
Cornelissen, Robin
Dingemans, Anne-Marie C
Bogers, Ad J J C
Mahtab, Edris A F
Journal Article
United States
2021/07/29
JTCVS Tech. 2021 Mar 16;7:309-321. doi: 10.1016/j.xjtc.2021.03.016. eCollection 2021 Jun.},
   abstract = {BACKGROUND: There has been an increasing trend toward pulmonary segmentectomies to treat early-stage lung cancer, small intrapulmonary metastases, and localized benign pathology. A complete preoperative understanding of pulmonary anatomy is essential for accurate surgical planning and case selection. Identifying intersegmental divisions is extremely difficult when performed on computed tomography. For the preoperative planning of segmentectomies, virtual reality (VR) and artificial intelligence could allow 3-dimensional visualization of the complex anatomy of pulmonary segmental divisions, vascular arborization, and bronchial anatomy. This technology can be applied by surgeons preoperatively to gain better insight into a patient's anatomy for planning segmentectomy. METHODS: In this prospective observational pilot study, we aim to assess and demonstrate the technical feasibility and clinical applicability of the first dedicated artificial intelligence-based and immersive 3-dimensional-VR platform (PulmoVR; jointly developed and manufactured by Department of Cardiothoracic Surgery [Erasmus Medical Center, Rotterdam, The Netherlands], MedicalVR [Amsterdam, The Netherlands], EVOCS Medical Image Communication [Fysicon BV, Oss, The Netherlands], and Thirona [Nijmegen, The Netherlands]) for preoperative planning of video-assisted thoracoscopic segmentectomies. RESULTS: A total of 10 eligible patients for segmentectomy were included in this study after referral through the institutional thoracic oncology multidisciplinary team. PulmoVR was successfully applied as a supplementary imaging tool to perform video-assisted thoracoscopic segmentectomies. In 40% of the cases, the surgical strategy was adjusted due to the 3-dimensional-VR-based evaluation of anatomy. This underlines the potential benefit of additional VR-guided planning of segmentectomy for both surgeon and patient. CONCLUSIONS: Our study demonstrates the successful development and clinical application of the first dedicated artificial intelligence and VR platform for the planning of pulmonary segmentectomy. This is the first study that shows an immersive virtual reality-based application for preoperative planning of segmentectomy to the best of our knowledge.},
   keywords = {2D, 2 dimensional
3D, 3 dimensional
AI, artificial intelligence
CT, computed tomography
DICOM, digital imaging and communication in medicine
NSCLC, non–small cell lung cancer
S, segment
VATS, video assisted thoracoscopic surgery
VR, virtual reality
lung cancer
preoperative planning
segmentectomy
video-assisted thoracoscopic surgery
virtual reality},
   ISSN = {2666-2507},
   DOI = {10.1016/j.xjtc.2021.03.016},
   year = {2021},
   type = {Journal Article}
}

@article{RN28,
   author = {Steineke, T. C. and Barbery, D.},
   title = {Microsurgical clipping of middle cerebral artery aneurysms: preoperative planning using virtual reality to reduce procedure time},
   journal = {Neurosurg Focus},
   volume = {51},
   number = {2},
   pages = {E12},
   note = {1092-0684
Steineke, Thomas C
Barbery, Daniela
Journal Article
United States
2021/08/02
Neurosurg Focus. 2021 Aug;51(2):E12. doi: 10.3171/2021.5.FOCUS21238.},
   abstract = {OBJECTIVE: The authors sought to evaluate the impact of virtual reality (VR) applications for preoperative planning and rehearsal on the total procedure time of microsurgical clipping of middle cerebral artery (MCA) ruptured and unruptured aneurysms compared with standard surgical planning. METHODS: A retrospective review of 21 patients from 2016 to 2019 was conducted to determine the impact on the procedure time of MCA aneurysm clipping after implementing VR for preoperative planning and rehearsal. The control group consisted of patients whose procedures were planned with standard CTA and DSA scans (n = 11). The VR group consisted of patients whose procedures were planned with a patient-specific 360° VR (360VR) model (n = 10). The 360VR model was rendered using CTA and DSA data when available. Each patient was analyzed and scored with a case complexity (CC) 5-point grading scale accounting for aneurysm size, incorporation of M2 branches, and aspect ratio, with 1 being the least complex and 5 being the most complex. The mean procedure times were compared between the VR group and the control group, as were the mean CC score between the groups. Comorbidities and aneurysm conduction (ruptured vs unruptured) were also taken into consideration for the comparison. RESULTS: The mean CC scores for the control group and VR group were 2.45 ± 1.13 and 2.30 ± 0.48, respectively. CC was not significantly different between the two groups (p = 0.69). The mean procedure time was significantly lower for the VR group compared with the control group (247.80 minutes vs 328.27 minutes; p = 0.0115), particularly for the patients with a CC score of 2 (95% CI, p = 0.0064). A Charlson Comorbidity Index score was also calculated for each group, but no statistical significance was found (VR group, 2.8 vs control group, 1.8, p = 0.14). CONCLUSIONS: In this study, usage of 360VR models for planning the craniotomy and rehearsing with various clip sizes and configurations resulted in an 80-minute decrease in procedure time. These findings have suggested the potential of VR technology in improving surgical efficiency for aneurysm clipping procedures regardless of complexity, while making the procedure faster and safer.},
   keywords = {*Aneurysm, Ruptured/surgery
Humans
*Intracranial Aneurysm/diagnostic imaging/surgery
Microsurgery
Neurosurgical Procedures
Retrospective Studies
Treatment Outcome
*Virtual Reality
craniotomy planning
microsurgical clipping
middle cerebral artery aneurysm
virtual reality},
   ISSN = {1092-0684},
   DOI = {10.3171/2021.5.Focus21238},
   year = {2021},
   type = {Journal Article}
}

@article{RN23,
   author = {Ujiie, H. and Yamaguchi, A. and Gregor, A. and Chan, H. and Kato, T. and Hida, Y. and Kaga, K. and Wakasa, S. and Eitel, C. and Clapp, T. R. and Yasufuku, K.},
   title = {Developing a virtual reality simulation system for preoperative planning of thoracoscopic thoracic surgery},
   journal = {J Thorac Dis},
   volume = {13},
   number = {2},
   pages = {778-783},
   note = {2077-6624
Ujiie, Hideki
Yamaguchi, Aogu
Gregor, Alexander
Chan, Harley
Kato, Tatsuya
Hida, Yasuhiro
Kaga, Kichizo
Wakasa, Satoru
Eitel, Chad
Clapp, Tod R
Yasufuku, Kazuhiro
Journal Article
China
2021/03/16
J Thorac Dis. 2021 Feb;13(2):778-783. doi: 10.21037/jtd-20-2197.},
   abstract = {BACKGROUND: Video-assisted thoracoscopic surgery (VATS) has become a standard approach for the treatment of lung cancer. However, its minimally invasive nature limits the field of view and reduces tactile feedback. These limitations make it vital that surgeons thoroughly familiarize themselves with the patient's anatomy preoperatively. We have developed a virtual reality (VR) surgical navigation system using head-mounted displays (HMD). The aim of this study was to investigate the potential utility of this VR simulation system in both preoperative planning and intraoperative assistance, including support during thoracoscopic sublobar resection. METHODS: Three-dimensional (3D) polygon data derived from preoperative computed tomography data was loaded into BananaVision software developed at Colorado State University and displayed on an HMD. An interactive 3D reconstruction image was created, in which all the pulmonary structures could be individually imaged. Preoperative resection simulations were performed with patient-individualized reconstructed 3D images. RESULTS: The 3D anatomic structure of pulmonary vessels and a clear vision into the space between the lesion and adjacent tissues were successfully appreciated during preoperative simulation. Surgeons could easily evaluate the real patient's anatomy in preoperative simulations to improve the accuracy and safety of actual surgery. The VR software and HMD allowed surgeons to visualize and interact with real patient data in true 3D providing a unique perspective. CONCLUSIONS: This initial experience suggests that a VR simulation with HMD facilitated preoperative simulation. Routine imaging modalities combined with VR systems could substantially improve preoperative planning and contribute to the safety and accuracy of anatomic resection.},
   keywords = {Virtual reality (VR)
augmented reality (AR)
head-mounted display (HMD)
segmentectomy
video-assisted thoracoscopic surgery (VATS)},
   ISSN = {2072-1439 (Print)
2072-1439},
   DOI = {10.21037/jtd-20-2197},
   year = {2021},
   type = {Journal Article}
}

@article{RN17,
   author = {Abjigitova, D. and Sadeghi, A. H. and Peek, J. J. and Bekkers, J. A. and Bogers, Ajjc and Mahtab, E. A. F.},
   title = {Virtual Reality in the Preoperative Planning of Adult Aortic Surgery: A Feasibility Study},
   journal = {J Cardiovasc Dev Dis},
   volume = {9},
   number = {2},
   note = {2308-3425
Abjigitova, Djamila
Sadeghi, Amir H
Peek, Jette J
Orcid: 0000-0002-8412-2851
Bekkers, Jos A
Bogers, Ad J J C
Mahtab, Edris A F
Orcid: 0000-0003-2647-5509
Journal Article
Switzerland
2022/02/25
J Cardiovasc Dev Dis. 2022 Jan 18;9(2):31. doi: 10.3390/jcdd9020031.},
   abstract = {Background: Complex aortic anatomy needs careful preoperative planning in which a patient-tailored approach with novel immersive techniques could serve as a valuable addition to current preoperative imaging. This pilot study aimed to investigate the technical feasibility of virtual reality (VR) as an additional imaging tool for preoperative planning in ascending aortic surgery. Methods: Ten cardiothoracic surgeons were presented with six patients who had each undergone a recent repair of the ascending aorta. Two-dimensional computed tomography images of each patient were assessed prior to the VR session. After three-dimensional (3D) VR rendering and 3D segmentation of the ascending aorta and aortic arch, the reconstructions were analyzed by each surgeon in VR via a head-mounted display. Each cardiothoracic surgeon completed a questionnaire after each planning procedure. The results of their assessments were compared to the performed operations. The primary endpoint of the present study was a change of surgical approach from open to clamped distal anastomosis, and vice versa. Results: Compared with conventional imaging, 80% of surgeons found that VR prepared them better for surgery. In 33% of cases (two out of six), the preoperative decision was adjusted due to the 3D VR-based evaluation of the anatomy. Surgeons rated CardioVR usefulness, user-friendliness, and satisfaction with median scores of 3.8 (IQR: 3.5-4.1), 4.2 (IQR: 3.8-4.6,) and 4.1 (IQR: 3.8-4.7) on a five-point Likert scale, respectively. Conclusions: Three-dimensional VR imaging was associated with improved anatomical understanding among surgeons and could be helpful in the future preoperative planning of ascending aortic surgery.},
   keywords = {aortic arch surgery
ascending aorta
surgical planning
virtual reality},
   ISSN = {2308-3425},
   DOI = {10.3390/jcdd9020031},
   year = {2022},
   type = {Journal Article}
}

@article{RN32,
   author = {Arjomandi Rad, A. and Vardanyan, R. and Thavarajasingam, S. G. and Zubarevich, A. and Van den Eynde, J. and Sá, Mpbo and Zhigalov, K. and Sardiari Nia, P. and Ruhparwar, A. and Weymann, A.},
   title = {Extended, virtual and augmented reality in thoracic surgery: a systematic review},
   journal = {Interact Cardiovasc Thorac Surg},
   volume = {34},
   number = {2},
   pages = {201-211},
   note = {1569-9285
Arjomandi Rad, Arian
Orcid: 0000-0002-4931-4049
Vardanyan, Robert
Orcid: 0000-0002-8111-2084
Thavarajasingam, Santhosh G
Zubarevich, Alina
Orcid: 0000-0002-2444-5747
Van den Eynde, Jef
Orcid: 0000-0002-5606-376x
Sá, Michel Pompeu B O
Zhigalov, Konstantin
Orcid: 0000-0002-6440-3736
Sardiari Nia, Peyman
Ruhparwar, Arjang
Orcid: 0000-0003-2725-9912
Weymann, Alexander
Orcid: 0000-0003-2966-6159
Journal Article
Systematic Review
England
2021/09/21
Interact Cardiovasc Thorac Surg. 2022 Jan 18;34(2):201-211. doi: 10.1093/icvts/ivab241.},
   abstract = {OBJECTIVES: Extended reality (XR), encompassing both virtual reality (VR) and augmented reality, allows the user to interact with a computer-generated environment based on reality. In essence, the immersive nature of VR and augmented reality technology has been warmly welcomed in all aspects of medicine, gradually becoming increasingly feasible to incorporate into everyday practice. In recent years, XR has become increasingly adopted in thoracic surgery, although the extent of its applications is unclear. Here, we aim to review the current applications of XR in thoracic surgery. METHODS: A systematic database search was conducted of original articles that explored the use of VR and/or augmented reality in thoracic surgery in EMBASE, MEDLINE, Cochrane database and Google Scholar, from inception to December 2020. RESULTS: Our search yielded 1494 citations, of which 21 studies published from 2007 to 2019 were included in this review. Three main areas were identified: (i) the application of XR in thoracic surgery training; (ii) preoperative planning of thoracic procedures; and (iii) intraoperative assistance. Overall, XR could produce progression along the learning curve, enabling trainees to reach acceptable standards before performing in the operating theatre. Preoperatively, through the generation of 3D-renderings of the thoracic cavity and lung anatomy, VR increases procedural accuracy and surgical confidence through familiarization of the patient's anatomy. XR-assisted surgery may have therapeutic use particularly for complex cases, where conventional methods would yield inadequate outcomes due to inferior accuracy. CONCLUSION: XR represents a salient step towards improving thoracic surgical training, as well as enhancing preoperative planning and intraoperative guidance.},
   keywords = {*Augmented Reality
Humans
Operating Rooms
*Thoracic Surgery
*Thoracic Surgical Procedures
*Virtual Reality
Augmented reality
Extended reality
Surgical simulation
Thoracic surgery
Virtual reality},
   ISSN = {1569-9293 (Print)
1569-9285},
   DOI = {10.1093/icvts/ivab241},
   year = {2022},
   type = {Journal Article}
}

@article{RN14,
   author = {Bakhuis, W. and Kersten, C. M. and Sadeghi, A. H. and Mank, Q. J. and Wijnen, R. M. H. and Ciet, P. and Bogers, Ajjc and Schnater, J. M. and Mahtab, E. A. F.},
   title = {Preoperative visualization of congenital lung abnormalities: hybridizing artificial intelligence and virtual reality},
   journal = {Eur J Cardiothorac Surg},
   volume = {63},
   number = {1},
   note = {1873-734x
Bakhuis, Wouter
Orcid: 0000-0002-3233-4182
Kersten, Casper M
Orcid: 0000-0002-6514-086x
Sadeghi, Amir H
Orcid: 0000-0002-6118-2341
Mank, Quinten J
Wijnen, René M H
Ciet, Pierluigi
Bogers, Ad J J C
Orcid: 0000-0001-6200-1998
Schnater, J Marco
Mahtab, Edris A F
Orcid: 0000-0003-2647-5509
Erasmus University Medical Center/
Journal Article
Germany
2023/01/17
Eur J Cardiothorac Surg. 2022 Dec 2;63(1):ezad014. doi: 10.1093/ejcts/ezad014.},
   abstract = {OBJECTIVES: When surgical resection is indicated for a congenital lung abnormality (CLA), lobectomy is often preferred over segmentectomy, mostly because the latter is associated with more residual disease. Presumably, this occurs in children because sublobar surgery often does not adhere to anatomical borders (wedge resection instead of segmentectomy), thus increasing the risk of residual disease. This study investigated the feasibility of identifying eligible cases for anatomical segmentectomy by combining virtual reality (VR) and artificial intelligence (AI). METHODS: Semi-automated segmentation of bronchovascular structures and lesions were visualized with VR and AI technology. Two specialists independently evaluated via a questionnaire the informative value of regular computed tomography versus three-dimensional (3D) VR images. RESULTS: Five asymptomatic, non-operated cases were selected. Bronchovascular segmentation, volume calculation and image visualization in the VR environment were successful in all cases. Based on the computed tomography images, assignment of the CLA lesion to specific lung segments matched between the consulted specialists in only 1 out of the cases. Based on the three 3D VR images, however, the localization matched in 3 of the 5 cases. If the patients would have been operated, adding the 3D VR tool to the preoperative workup would have resulted in changing the surgical strategy (i.e. lobectomy versus segmentectomy) in 4 cases. CONCLUSIONS: This study demonstrated the technical feasibility of a hybridized AI-VR visualization of segment-level lung anatomy in patients with CLA. Further exploration of the value of 3D VR in identifying eligible cases for anatomical segmentectomy is therefore warranted.},
   keywords = {Child
Humans
*Lung Neoplasms/surgery
Artificial Intelligence
*Carcinoma, Non-Small-Cell Lung/surgery
*Virtual Reality
Lung/diagnostic imaging/surgery/pathology
Congenital lung abnormalities
Congenital pulmonary airway malformations
Paediatric lung surgery
Segmentectomy
Virtual reality},
   ISSN = {1010-7940 (Print)
1010-7940},
   DOI = {10.1093/ejcts/ezad014},
   year = {2022},
   type = {Journal Article}
}

@article{RN46,
   author = {Fujihara, A. and Ukimura, O.},
   title = {Virtual reality of three-dimensional surgical field for surgical planning and intraoperative management},
   journal = {World J Urol},
   volume = {40},
   number = {3},
   pages = {687-696},
   note = {1433-8726
Fujihara, Atsuko
Ukimura, Osamu
Orcid: 0000-0003-3443-3210
Journal Article
Germany
2021/11/18
World J Urol. 2022 Mar;40(3):687-696. doi: 10.1007/s00345-021-03841-z. Epub 2021 Nov 17.},
   abstract = {PURPOSE: To investigate the impact of virtual reality (VR) technologies on urological surgeries, specifically in the management of prostate cancer and renal cancer. METHODS: A non-systematic review of the literature was performed. Medline, Pubmed, and the Cochrane Database were screened for studies regarding the use of VR technologies in the management of prostate and renal cancer. RESULTS: In the management of prostate cancer, VR technologies have been increasingly applied for diagnosis with magnetic resonance imaging/ultrasound fusion biopsy, surgical training using a simulator, surgical navigation in robot-assisted radical prostatectomy, and targeted focal therapy. In partial nephrectomy, surgical simulation and intra-surgical guidance with three-dimensional VR have been used for better understanding of the hilar vascular information, tumor location, and positional relationships of the tumor-feeding vessel and pyelocaliceal system. CONCLUSIONS: VR contributes to the education, training, and simulation of surgical procedures as well as helping the surgeons to tailor surgical planning on each patient. Further prospective studies are needed to assess the beneficial impacts of this technology for both the physician and patient by objective parameters.},
   keywords = {Humans
Imaging, Three-Dimensional
Male
Nephrectomy/methods
Prostatectomy/methods
*Robotic Surgical Procedures/methods
*Virtual Reality
Partial nephrectomy
Radical prostatectomy
Urological surgery
Virtual reality},
   ISSN = {0724-4983},
   DOI = {10.1007/s00345-021-03841-z},
   year = {2022},
   type = {Journal Article}
}

@article{RN15,
   author = {Kim, B. and Nguyen, P. and Loke, Y. H. and Cleveland, V. and Liu, X. and Mass, P. and Hibino, N. and Olivieri, L. and Krieger, A.},
   title = {Virtual Reality Cardiac Surgical Planning Software (CorFix) for Designing Patient-Specific Vascular Grafts: Development and Pilot Usability Study},
   journal = {JMIR Cardio},
   volume = {6},
   number = {1},
   pages = {e35488},
   note = {2561-1011
Kim, Byeol
Orcid: 0000-0001-8289-9424
Nguyen, Phong
Orcid: 0000-0002-0737-2064
Loke, Yue-Hin
Orcid: 0000-0003-1003-1903
Cleveland, Vincent
Orcid: 0000-0001-8235-9962
Liu, Xiaolong
Orcid: 0000-0001-5335-3473
Mass, Paige
Orcid: 0000-0002-5778-9300
Hibino, Narutoshi
Orcid: 0000-0003-4551-9079
Olivieri, Laura
Orcid: 0000-0002-3783-0783
Krieger, Axel
Orcid: 0000-0001-8169-075x
R01 HL143468/HL/NHLBI NIH HHS/United States
R21 HD090671/HD/NICHD NIH HHS/United States
R33 HD090671/HD/NICHD NIH HHS/United States
Journal Article
Canada
2022/06/18
JMIR Cardio. 2022 Jun 17;6(1):e35488. doi: 10.2196/35488.},
   abstract = {BACKGROUND: Patients with single ventricle heart defects receive 3 stages of operations culminating in the Fontan procedure. During the Fontan procedure, a vascular graft is sutured between the inferior vena cava and pulmonary artery to divert deoxygenated blood flow to the lungs via passive flow. Customizing the graft configuration can maximize the long-term benefits. However, planning patient-specific procedures has several challenges, including the ability for physicians to customize grafts and evaluate their hemodynamic performance. OBJECTIVE: The aim of this study was to develop a virtual reality (VR) Fontan graft modeling and evaluation software for physicians. A user study was performed to achieve 2 additional goals: (1) to evaluate the software when used by medical doctors and engineers, and (2) to explore the impact of viewing hemodynamic simulation results in numerical and graphical formats. METHODS: A total of 5 medical professionals including 4 physicians (1 fourth-year resident, 1 third-year cardiac fellow, 1 pediatric intensivist, and 1 pediatric cardiac surgeon) and 1 biomedical engineer voluntarily participated in the study. The study was pre-scripted to minimize the variability of the interactions between the experimenter and the participants. All participants were trained to use the VR gear and our software, CorFix. Each participant designed 1 bifurcated and 1 tube-shaped Fontan graft for a single patient. A hemodynamic performance evaluation was then completed, allowing the participants to further modify their tube-shaped design. The design time and hemodynamic performance for each graft design were recorded. At the end of the study, all participants were provided surveys to evaluate the usability and learnability of the software and rate the intensity of VR sickness. RESULTS: The average times for creating 1 bifurcated and 1 tube-shaped graft after a single 10-minute training session were 13.40 and 5.49 minutes, respectively, with 3 out 5 bifurcated and 1 out of 5 tube-shaped graft designs being in the benchmark range of hepatic flow distribution. Reviewing hemodynamic performance results and modifying the tube-shaped design took an average time of 2.92 minutes. Participants who modified their tube-shaped graft designs were able to improve the nonphysiologic wall shear stress (WSS) percentage by 7.02%. All tube-shaped graft designs improved the WSS percentage compared to the native surgical case of the patient. None of the designs met the benchmark indexed power loss. CONCLUSIONS: VR graft design software can quickly be taught to physicians with no engineering background or VR experience. Improving the CorFix system could improve performance of the users in customizing and optimizing grafts for patients. With graphical visualization, physicians were able to improve WSS percentage of a tube-shaped graft, lowering the chance of thrombosis. Bifurcated graft designs showed potential strength in better flow split to the lungs, reducing the risk for pulmonary arteriovenous malformations.},
   keywords = {congenital heart disease
heart
surgery
surgical planning
usability study
virtual reality},
   ISSN = {2561-1011},
   DOI = {10.2196/35488},
   year = {2022},
   type = {Journal Article}
}

@article{RN41,
   author = {Peek, J. J. and Sadeghi, A. H. and Maat, Apwm and Rothbarth, J. and Mureau, M. A. M. and Verhoef, C. and Bogers, Ajjc},
   title = {Multidisciplinary Virtual Three-Dimensional Planning of a Forequarter Amputation With Chest Wall Resection},
   journal = {Ann Thorac Surg},
   volume = {113},
   number = {1},
   pages = {e13-e16},
   note = {1552-6259
Peek, Jette J
Sadeghi, Amir H
Maat, Alexander P W M
Rothbarth, Joost
Mureau, Marc A M
Verhoef, Cornelis
Bogers, Ad J J C
Case Reports
Journal Article
Netherlands
2021/04/22
Ann Thorac Surg. 2022 Jan;113(1):e13-e16. doi: 10.1016/j.athoracsur.2021.04.014. Epub 2021 Apr 18.},
   abstract = {We present the case of a 74-year-old man with a history of a squamous cell carcinoma in the left axilla. The patient underwent a multidisciplinary surgical resection through an extended forequarter amputation with thoracic wall resection and reconstruction. With regard to the complexity of the case, three-dimensional virtual reality-based patient-specific reconstructions were used as a supplemental tool to conventional computed tomography imaging to plan the procedure. With this report, we aim to stimulate further research to improve and automate the workflow and to bring virtual and augmented reality reconstructions into the surgical theater of the future.},
   keywords = {Aged
*Axilla
Carcinoma, Squamous Cell/diagnostic imaging/*surgery
Humans
*Imaging, Three-Dimensional
Male
*Patient Care Planning
Patient Care Team
Plastic Surgery Procedures
Soft Tissue Neoplasms/diagnostic imaging/*surgery
Thoracic Surgical Procedures/*methods
Thoracic Wall/diagnostic imaging/*surgery
*Virtual Reality},
   ISSN = {0003-4975},
   DOI = {10.1016/j.athoracsur.2021.04.014},
   year = {2022},
   type = {Journal Article}
}

@article{RN18,
   author = {Pelizzo, G. and Costanzo, S. and Roveri, M. and Lanfranchi, G. and Vertemati, M. and Milani, P. and Zuccotti, G. and Cassin, S. and Panfili, S. and Rizzetto, F. and Campari, A. and Camporesi, A. and Calcaterra, V.},
   title = {Developing Virtual Reality Head Mounted Display (HMD) Set-Up for Thoracoscopic Surgery of Complex Congenital Lung MalFormations in Children},
   journal = {Children (Basel)},
   volume = {9},
   number = {1},
   note = {2227-9067
Pelizzo, Gloria
Costanzo, Sara
Roveri, Margherita
Lanfranchi, Giulia
Vertemati, Maurizio
Orcid: 0000-0003-0012-1366
Milani, Paolo
Zuccotti, Gianvincenzo
Orcid: 0000-0002-2795-9874
Cassin, Simone
Panfili, Sebastiano
Rizzetto, Francesco
Orcid: 0000-0003-3451-9874
Campari, Alessandro
Camporesi, Anna
Orcid: 0000-0002-1160-1456
Calcaterra, Valeria
Orcid: 0000-0002-2137-5974
Journal Article
Switzerland
2022/01/22
Children (Basel). 2022 Jan 3;9(1):50. doi: 10.3390/children9010050.},
   abstract = {Video assisted thoracoscopic surgery (VATS) has been adopted in pediatric age for the treatment of congenital lung malformations (CLM). The success of VATS in pediatrics largely depends on the surgeon's skill ability to understand the airways, vascular system and lung parenchyma anatomy in CLM. In the last years, virtual reality (VR) and 3-dimensional (3D) printing of organ models and VR head mounted display (HMD) technologies have been introduced for completion of preoperative planning in adult patients. To date no reports about the use of VR HMD technologies in a pediatric setting are available. The aim of this report is to introduce a VR HMD model in VATS procedure to improve the quality of care in children with CLM. VR HMD set-up for planning thoracoscopic surgery was performed in a series of pediatric patients with diagnosis of CLM. The preoperative VR HMD evaluation allowed a navigation into the malformation with the aim to explore, interact, and make the surgeon more confident and skilled to answer to the traps. A development of surgical simulations models and teaching program dedicated to education and training in pediatric VATS is suitable among the pediatric surgery community. Further studies should demonstrate all the benefits of such technology in pediatric patients submitted to VATS procedure.},
   keywords = {children
congenital lung malformation
pediatric surgery
thoracoscopic surgery
virtual reality},
   ISSN = {2227-9067 (Print)
2227-9067},
   DOI = {10.3390/children9010050},
   year = {2022},
   type = {Journal Article}
}

@article{RN24,
   author = {Sadeghi, A. H. and Mathari, S. E. and Abjigitova, D. and Maat, Apwm and Taverne, Yjhj and Bogers, Ajjc and Mahtab, E. A. F.},
   title = {Current and Future Applications of Virtual, Augmented, and Mixed Reality in Cardiothoracic Surgery},
   journal = {Ann Thorac Surg},
   volume = {113},
   number = {2},
   pages = {681-691},
   note = {1552-6259
Sadeghi, Amir H
Mathari, Sulayman El
Abjigitova, Djamila
Maat, Alexander P W M
Taverne, Yannick J H J
Bogers, Ad J J C
Mahtab, Edris A F
Journal Article
Review
Netherlands
2020/12/22
Ann Thorac Surg. 2022 Feb;113(2):681-691. doi: 10.1016/j.athoracsur.2020.11.030. Epub 2020 Dec 19.},
   abstract = {BACKGROUND: This review aims to examine the existing literature to address currently used virtual, augmented, and mixed reality modalities in the areas of preoperative surgical planning, intraoperative guidance, and postoperative management in the field of cardiothoracic surgery. In addition this innovative technology provides future perspectives and potential benefits for cardiothoracic surgeons, trainees, and patients. METHODS: A targeted, nonsystematic literature assessment was performed within the Medline and Google Scholar databases to help identify current trends and to provide better understanding of the current state-of-the-art extended reality (XR) modalities in cardiothoracic surgery. Related articles published up to July 2020 were included in the review. RESULTS: XR is a novel technique gaining increasing application in cardiothoracic surgery. It provides a 3-dimensional and realistic view of structures and environments and offers the user the ability to interact with digital projections of surgical targets. Recent studies showed the validity and benefits of XR applications in cardiothoracic surgery. Examples include XR-guided preoperative planning, intraoperative guidance and navigation, postoperative pain and rehabilitation management, surgical simulation, and patient education. CONCLUSIONS: XR is gaining interest in the field of cardiothoracic surgery. In particular there are promising roles for XR applications in televirtuality, surgical planning, surgical simulation, and perioperative management. However future refinement and research are needed to further implement XR in the aforementioned settings within cardiothoracic surgery.},
   keywords = {*Augmented Reality
Computer Simulation/*trends
Education, Medical, Graduate/*methods/trends
Humans
Specialties, Surgical/*education
Thoracic Surgery/*education
*Virtual Reality},
   ISSN = {0003-4975},
   DOI = {10.1016/j.athoracsur.2020.11.030},
   year = {2022},
   type = {Journal Article}
}

@article{RN44,
   author = {Thumerel, M. and Belaroussi, Y. and Prisciandaro, E. and Chermat, A. and Zarrouki, S. and Chevalier, B. and Rodriguez, A. and Hustache-Castaing, R. and Jougon, J.},
   title = {Immersive Three-dimensional Computed Tomography to Plan Chest Wall Resection for Lung Cancer},
   journal = {Ann Thorac Surg},
   volume = {114},
   number = {6},
   pages = {2379-2382},
   note = {1552-6259
Thumerel, Matthieu
Belaroussi, Yaniss
Prisciandaro, Elena
Chermat, Anaelle
Zarrouki, Sarah
Chevalier, Benjamin
Rodriguez, Arnaud
Hustache-Castaing, Romain
Jougon, Jacques
Journal Article
Netherlands
2022/08/14
Ann Thorac Surg. 2022 Dec;114(6):2379-2382. doi: 10.1016/j.athoracsur.2022.06.059. Epub 2022 Aug 10.},
   abstract = {PURPOSE: Chest wall resections for lung cancer treatment remain difficult to plan using standard 2-dimensional computed tomography. Although virtual reality headsets have been used in many medical contexts, they have not been used in chest wall resection planning. DESCRIPTION: We compared preoperative planning of a chest wall surgical resection for lung cancer treatment between senior and resident surgeons who used an immersive virtual reality device and a 2-dimensional computed tomography. EVALUATION: Chest wall resection planning was more accurate when surgeons used virtual reality vs computed tomography analysis (28.6% vs 18.3%, P = .018), and this was particularly true in the resident surgeon group (27.4% vs 8.3%, P = .0025). Predictions regarding the need for chest wall substitutes were also more accurate when they were made using virtual reality vs computed tomography analysis in all groups (96% vs 68.5%, P < .0001). Other studied parameters were not affected by the use of the virtual reality tool. CONCLUSIONS: Virtual reality may offer enhanced accuracy for chest wall resection and reconstruction planning for lung cancer treatment.},
   keywords = {Humans
*Thoracic Wall/diagnostic imaging/surgery
Tomography, X-Ray Computed/methods
*Lung Neoplasms/diagnostic imaging/surgery
*Thoracic Surgical Procedures/methods
*Thoracoplasty
Imaging, Three-Dimensional},
   ISSN = {0003-4975},
   DOI = {10.1016/j.athoracsur.2022.06.059},
   year = {2022},
   type = {Journal Article}
}

@inproceedings{RN9,
   author = {Tucker, N. and Sutton, B. P. and Duncan, C. and Lu, C. and Koyejo, S. and Tsung, A. J. and Maksimovic, J. and Ralph, T. and Pieta, S. M. and Bramlet, M. T.},
   title = {Fully Automated Conversion Of Glioma Clinical MRI Scans Into A 3D Virtual Reality Model For Presurgical Planning},
   booktitle = {2022 Annual Modeling and Simulation Conference (ANNSIM)},
   pages = {392-403},
   DOI = {10.23919/ANNSIM55834.2022.9859317},
   type = {Conference Proceedings}
}

@article{RN13,
   author = {Bakhuis, W. and Sadeghi, A. H. and Moes, I. and Maat, Apwm and Siregar, S. and Bogers, Ajjc and Mahtab, E. A. F.},
   title = {Essential Surgical Plan Modifications After Virtual Reality Planning in 50 Consecutive Segmentectomies},
   journal = {Ann Thorac Surg},
   volume = {115},
   number = {5},
   pages = {1247-1255},
   note = {1552-6259
Bakhuis, Wouter
Sadeghi, Amir H
Moes, Iris
Maat, Alexander P W M
Siregar, Sabrina
Bogers, Ad J J C
Mahtab, Edris A F
Journal Article
Netherlands
2022/09/10
Ann Thorac Surg. 2023 May;115(5):1247-1255. doi: 10.1016/j.athoracsur.2022.08.037. Epub 2022 Sep 6.},
   abstract = {BACKGROUND: Lately, increased interest in pulmonary segmentectomy has been observed. Segmental border identification is extremely difficult on 2-dimensional computed tomography (CT). Preoperative application of virtual reality (VR) can provide better insight into patient-specific anatomy. The aim of this study was to investigate the added clinical value of 3-dimensional (3D) VR using PulmoVR for preoperative planning. METHODS: Patients with an indication for pulmonary segmentectomy were included between June 2020 and September 2021 at the Erasmus Medical Center, Rotterdam, The Netherlands. CT scans were (semi)automatically segmented to visualize lung segments, segmental arteries, veins, and bronchi. Three surgeons made a surgical plan on the basis of the conventional CT scan and subsequently analyzed the VR visualization. The primary outcome was the incidence of critical (ensuring radical resection) preoperative plan modifications. Secondarily, data on observed anatomic variation and perioperative (oncologic) outcomes were collected. RESULTS: A total of 50 patients (median age at surgery, 65 years [interquartile range, 17.25 years]) with an indication for pulmonary segmentectomy were included. After supplemental VR visualization, the surgical plan was adjusted in 52%; the tumor was localized in a different segment in 14%, more lung-sparing resection was planned in 10%, and extended segmentectomy, including 1 lobectomy, was planned in 28%. Pathologic examination confirmed radical resection in 49 patients (98%). CONCLUSIONS: This 3D VR technology showed added clinical value in the first 50 VR-guided segmentectomies because a 52% change of plan with 98% radical resection was observed. Furthermore, 3D VR visualization of the bronchovasculature, including various anatomic variations, provided better insight into patient-specific anatomy and offered lung-sparing possibilities with more certainty.},
   keywords = {Humans
Adolescent
Pneumonectomy/methods
Mastectomy, Segmental
Lung/surgery
*Lung Neoplasms/diagnostic imaging/surgery/pathology
*Virtual Reality
Imaging, Three-Dimensional/methods},
   ISSN = {0003-4975},
   DOI = {10.1016/j.athoracsur.2022.08.037},
   year = {2023},
   type = {Journal Article}
}

@inbook{RN21,
   author = {Garland, Michael and Heckbert, Paul S.},
   title = {Surface Simplification Using Quadric Error Metrics},
   booktitle = {Seminal Graphics Papers: Pushing the Boundaries, Volume 2},
   publisher = {Association for Computing Machinery},
   volume = {Volume 2},
   pages = {Article 15},
   ISBN = {9798400708978},
   DOI = {10.1145/3596711.3596727},
   url = {https://doi.org/10.1145/3596711.3596727},
   year = {2023},
   type = {Book Section}
}

@article{RN38,
   author = {Lan, L. and Mao, R. Q. and Qiu, R. Y. and Kay, J. and de Sa, D.},
   title = {Immersive Virtual Reality for Patient-Specific Preoperative Planning: A Systematic Review},
   journal = {Surg Innov},
   volume = {30},
   number = {1},
   pages = {109-122},
   note = {1553-3514
Lan, Lucy
Orcid: 0000-0003-4474-6018
Mao, Randi Q
Qiu, Reva Y
Kay, Jeffrey
de Sa, Darren
Journal Article
Systematic Review
United States
2022/12/01
Surg Innov. 2023 Feb;30(1):109-122. doi: 10.1177/15533506221143235. Epub 2022 Nov 30.},
   abstract = {Background. Immersive virtual reality (iVR) facilitates surgical decision-making by enabling surgeons to interact with complex anatomic structures in realistic 3-dimensional environments. With emerging interest in its applications, its effects on patients and providers should be clarified. This systematic review examines the current literature on iVR for patient-specific preoperative planning. Materials and Methods. A literature search was performed on five databases for publications from January 1, 2000 through March 21, 2021. Primary studies on the use of iVR simulators by surgeons at any level of training for patient-specific preoperative planning were eligible. Two reviewers independently screened titles, abstracts, and full texts, extracted data, and assessed quality using the Quality Assessment Tool for Studies with Diverse Designs (QATSDD). Results were qualitatively synthesized, and descriptive statistics were calculated. Results. The systematic search yielded 2,555 studies in total, with 24 full-texts subsequently included for qualitative synthesis, representing 264 medical personnel and 460 patients. Neurosurgery was the most frequently represented discipline (10/24; 42%). Preoperative iVR did not significantly improve patient-specific outcomes of operative time, blood loss, complications, and length of stay, but may decrease fluoroscopy time. In contrast, iVR improved surgeon-specific outcomes of surgical strategy, anatomy visualization, and confidence. Validity, reliability, and feasibility of patient-specific iVR models were assessed. The mean QATSDD score of included studies was 32.9%. Conclusions. Immersive VR improves surgeon experiences of preoperative planning, with minimal evidence for impact on short-term patient outcomes. Future work should focus on high-quality studies investigating long-term patient outcomes, and utility of preoperative iVR for trainees.},
   keywords = {Humans
Reproducibility of Results
*Virtual Reality
Neurosurgical Procedures/education
*Neurosurgery
*Surgeons
ergonomics and/or human factors study
image guided surgery
radiologist
simulation
surgical education},
   ISSN = {1553-3506 (Print)
1553-3506},
   DOI = {10.1177/15533506221143235},
   year = {2023},
   type = {Journal Article}
}

@article{RN51,
   author = {Edelmers, Edgars and Kazoka, Dzintra and Bolocko, Katrina and Sudars, Kaspars and Pilmane, Mara},
   title = {Automatization of CT Annotation: Combining AI Efficiency with Expert Precision},
   journal = {Diagnostics},
   volume = {14},
   number = {2},
   pages = {185},
   ISSN = {2075-4418},
   url = {https://www.mdpi.com/2075-4418/14/2/185},
   year = {2024},
   type = {Journal Article}
}

@article{RN16,
   author = {Munawar, Adnan and Li, Zhaoshuo and Nagururu, Nimesh and Trakimas, Danielle and Kazanzides, Peter and Taylor, Russell H. and Creighton, Francis X.},
   title = {Fully immersive virtual reality for skull-base surgery: surgical training and beyond},
   journal = {International Journal of Computer Assisted Radiology and Surgery},
   volume = {19},
   number = {1},
   pages = {51-59},
   abstract = {A virtual reality (VR) system, where surgeons can practice procedures on virtual anatomies, is a scalable and cost-effective alternative to cadaveric training. The fully digitized virtual surgeries can also be used to assess the surgeon’s skills using measurements that are otherwise hard to collect in reality. Thus, we present the Fully Immersive Virtual Reality System (FIVRS) for skull-base surgery, which combines surgical simulation software with a high-fidelity hardware setup.},
   ISSN = {1861-6429},
   DOI = {10.1007/s11548-023-02956-5},
   url = {https://doi.org/10.1007/s11548-023-02956-5},
   year = {2024},
   type = {Journal Article}
}

@article{RN5,
   author = {Preukschas, A. A. and Wise, P. A. and Bettscheider, L. and Pfeiffer, M. and Wagner, M. and Huber, M. and Golriz, M. and Fischer, L. and Mehrabi, A. and Rössler, F. and Speidel, S. and Hackert, T. and Müller-Stich, B. P. and Nickel, F. and Kenngott, H. G.},
   title = {Comparing a virtual reality head-mounted display to on-screen three-dimensional visualization and two-dimensional computed tomography data for training in decision making in hepatic surgery: a randomized controlled study},
   journal = {Surg Endosc},
   volume = {38},
   number = {5},
   pages = {2483-2496},
   note = {1432-2218
Preukschas, Anas Amin
Wise, Philipp Anthony
Bettscheider, Lisa
Pfeiffer, Micha
Wagner, Martin
Huber, Matthias
Golriz, Mohammad
Fischer, Lars
Mehrabi, Arianeb
Rössler, Fabian
Speidel, Stefanie
Hackert, Thilo
Müller-Stich, Beat Peter
Nickel, Felix
Kenngott, Hannes Götz
SFB 125/Deutsche Forschungsgemeinschaft/
Comparative Study
Journal Article
Randomized Controlled Trial
Germany
2024/03/08
Surg Endosc. 2024 May;38(5):2483-2496. doi: 10.1007/s00464-023-10615-8. Epub 2024 Mar 8.},
   abstract = {OBJECTIVE: Evaluation of the benefits of a virtual reality (VR) environment with a head-mounted display (HMD) for decision-making in liver surgery. BACKGROUND: Training in liver surgery involves appraising radiologic images and considering the patient's clinical information. Accurate assessment of 2D-tomography images is complex and requires considerable experience, and often the images are divorced from the clinical information. We present a comprehensive and interactive tool for visualizing operation planning data in a VR environment using a head-mounted-display and compare it to 3D visualization and 2D-tomography. METHODS: Ninety medical students were randomized into three groups (1:1:1 ratio). All participants analyzed three liver surgery patient cases with increasing difficulty. The cases were analyzed using 2D-tomography data (group "2D"), a 3D visualization on a 2D display (group "3D") or within a VR environment (group "VR"). The VR environment was displayed using the "Oculus Rift ™" HMD technology. Participants answered 11 questions on anatomy, tumor involvement and surgical decision-making and 18 evaluative questions (Likert scale). RESULTS: Sum of correct answers were significantly higher in the 3D (7.1 ± 1.4, p < 0.001) and VR (7.1 ± 1.4, p < 0.001) groups than the 2D group (5.4 ± 1.4) while there was no difference between 3D and VR (p = 0.987). Times to answer in the 3D (6:44 ± 02:22 min, p < 0.001) and VR (6:24 ± 02:43 min, p < 0.001) groups were significantly faster than the 2D group (09:13 ± 03:10 min) while there was no difference between 3D and VR (p = 0.419). The VR environment was evaluated as most useful for identification of anatomic anomalies, risk and target structures and for the transfer of anatomical and pathological information to the intraoperative situation in the questionnaire. CONCLUSIONS: A VR environment with 3D visualization using a HMD is useful as a surgical training tool to accurately and quickly determine liver anatomy and tumor involvement in surgery.},
   keywords = {Humans
*Virtual Reality
*Imaging, Three-Dimensional
*Tomography, X-Ray Computed/methods
Female
Male
Hepatectomy/methods/education
Adult
Young Adult
Clinical Decision-Making
User-Computer Interface
Liver Neoplasms/surgery/diagnostic imaging
Head mounted display
Hepatic surgery training
Three dimensional visualization
Virtual reality},
   ISSN = {0930-2794 (Print)
0930-2794},
   DOI = {10.1007/s00464-023-10615-8},
   year = {2024},
   type = {Journal Article}
}

@article{RN2,
   author = {Queisner, M. and Eisenträger, K.},
   title = {Surgical planning in virtual reality: a systematic review},
   journal = {J Med Imaging (Bellingham)},
   volume = {11},
   number = {6},
   pages = {062603},
   note = {2329-4310
Queisner, Moritz
Orcid: 0000-0001-7917-9231
Eisenträger, Karl
Orcid: 0000-0001-8090-9246
Journal Article
Review
United States
2024/04/29
J Med Imaging (Bellingham). 2024 Nov;11(6):062603. doi: 10.1117/1.JMI.11.6.062603. Epub 2024 Apr 25.},
   abstract = {PURPOSE: Virtual reality (VR) technology has emerged as a promising tool for physicians, offering the ability to assess anatomical data in 3D with visuospatial interaction qualities. The last decade has witnessed a remarkable increase in the number of studies focusing on the application of VR to assess patient-specific image data. This systematic review aims to provide an up-to-date overview of the latest research on VR in the field of surgical planning. APPROACH: A comprehensive literature search was conducted based on the preferred reporting items for systematic reviews and meta-analyses covering the period from April 1, 2021 to May 10, 2023. It includes research articles reporting on preoperative surgical planning using patient-specific medical images in virtual reality using head-mounted displays. The review summarizes the current state of research in this field, identifying key findings, technologies, study designs, methods, and potential directions for future research. RESULTS: The selected studies show a positive impact on surgical decision-making and anatomy understanding compared to other visualization modalities. A substantial number of studies are reporting anecdotal evidence and case-specific outcomes. Notably, surgical planning using VR led to more frequent changes in surgical plans compared to planning with other visualization methods when surgeons reassessed their initial plans. VR demonstrated benefits in reducing planning time and improving spatial localization of pathologies. CONCLUSIONS: Results show that the application of VR for surgical planning is still in an experimental stage but is gradually advancing toward clinical use. The diverse study designs, methodologies, and varying reporting hinder a comprehensive analysis. Some findings lack statistical evidence and rely on subjective assumptions. To strengthen evaluation, future research should focus on refining study designs, improving technical reporting, defining visual and technical proficiency requirements, and enhancing VR software usability and design. Addressing these areas could pave the way for an effective implementation of VR in clinical settings.},
   keywords = {planning
surgery
systematic review
virtual reality},
   ISSN = {2329-4302 (Print)
2329-4302},
   DOI = {10.1117/1.Jmi.11.6.062603},
   year = {2024},
   type = {Journal Article}
}

@article{RN40,
   author = {Ujiie, H. and Chiba, R. and Yamaguchi, A. and Nomura, S. and Shiiya, H. and Fujiwara-Kuroda, A. and Kaga, K. and Eitel, C. and Clapp, T. R. and Kato, T.},
   title = {Developing a Virtual Reality Simulation System for Preoperative Planning of Robotic-Assisted Thoracic Surgery},
   journal = {J Clin Med},
   volume = {13},
   number = {2},
   note = {2077-0383
Ujiie, Hideki
Orcid: 0000-0001-6119-8776
Chiba, Ryohei
Yamaguchi, Aogu
Nomura, Shunsuke
Shiiya, Haruhiko
Fujiwara-Kuroda, Aki
Orcid: 0000-0002-6231-4844
Kaga, Kichizo
Eitel, Chad
Clapp, Tod R
Orcid: 0009-0008-9102-7896
Kato, Tatsuya
Journal Article
Switzerland
2024/01/26
J Clin Med. 2024 Jan 21;13(2):611. doi: 10.3390/jcm13020611.},
   abstract = {Background. Robotic-assisted thoracic surgery (RATS) is now standard for lung cancer treatment, offering advantages over traditional methods. However, RATS's minimally invasive approach poses challenges like limited visibility and tactile feedback, affecting surgeons' navigation through com-plex anatomy. To enhance preoperative familiarization with patient-specific anatomy, we devel-oped a virtual reality (VR) surgical navigation system. Using head-mounted displays (HMDs), this system provides a comprehensive, interactive view of the patient's anatomy pre-surgery, aiming to improve preoperative simulation and intraoperative navigation. Methods. We integrated 3D data from preoperative CT scans into Perspectus VR Education software, displayed via HMDs for in-teractive 3D reconstruction of pulmonary structures. This detailed visualization aids in tailored preoperative resection simulations. During RATS, surgeons access these 3D images through Tile-Pro(TM) multi-display for real-time guidance. Results. The VR system enabled precise visualization of pulmonary structures and lesion relations, enhancing surgical safety and accuracy. The HMDs offered true 3D interaction with patient data, facilitating surgical planning. Conclusions. VR sim-ulation with HMDs, akin to a robotic 3D viewer, offers a novel approach to developing robotic surgical skills. Integrated with routine imaging, it improves preoperative planning, safety, and accuracy of anatomical resections. This technology particularly aids in lesion identification in RATS, optimizing surgical outcomes.},
   keywords = {head-mounted display (HMD)
image guided surgery
robotic-assisted thoracic surgery (RATS)
segmentectomy
three-dimensional reconstruction
virtual reality (VR)},
   ISSN = {2077-0383 (Print)
2077-0383},
   DOI = {10.3390/jcm13020611},
   year = {2024},
   type = {Journal Article}
}



% Article within a journal
@article{koon,
    author  = {Koonin, E V and Altschul, S F and P Bork}, 
    title   = {BRCA1 protein products: functional motifs}, 
    journal = {Nat. Genet.}, 
    year    = {1996},
    volume  = {13}, 
    pages   = {266-267}
}    

%%%%%%%%
% Article within conference proceedings
@inproceedings{xjon,
    author    = {X Jones}, 
    title     = {Zeolites and synthetic mechanisms},
    booktitle = {Proceedings of the First National Conference on 
                Porous Sieves: 27-30 June 1996; Baltimore},
    year      = {1996},
    editor    = {Y Smith}, 
    pages     = {16-27},
}    

%%%%%%%%
%  Book chapter, or article within a book
@incollection{schn,
    author    = {E Schnepf}, 
    title     = {From prey via endosymbiont to plastids: 
             comparative studies in dinoflagellates},
    booktitle = {Origins of Plastids}, 
    editor    = {R A Lewin}, 
    publisher = {Chapman and Hall},
    pages     = {53-76}, 
    year      = {1993},
    address = {New York}, 
    edition = {2nd} 
}    

%%%%%%%%
% Complete book
@book{marg,
    author    = {L Margulis}, 
    title     = {Origin of Eukaryotic Cells},
    publisher = {Yale University Press}, 
    year      = {1970},
    address   = {New Haven} 
}


%%%%%%%%
% PHD Thesis
@phdthesis{koha,
    author = {R Kohavi}, 
    title  = {Wrappers for performance enhancement and
             obvious decision graphs},
    school = {Stanford University, Computer Science Department},
    year   = {1995}
}

%%%%%%%%
%  Miscellaneous: webpage link/urL, etc/
@misc{issnic,
    author  = {{ISSN International Centre}},
    title = {The ISSN register},
    url = {http://www.issn.org},
    year = {2006},
    urldate={Accessed 20 Feb 2007}
}

